{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BMkggI0UEF75",
        "oMbXpzbJrTXu",
        "FpABLwkch--1",
        "VUmCCgly0UQo",
        "400PGfwc-iJC",
        "9ZV5aTuuGkGH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f343cdc988b743dab26a1070f952e450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d5bdaa13c5f4ebf8b4053183bc327d0",
              "IPY_MODEL_7c0f438da24a40c98d15cf7aae3cd598",
              "IPY_MODEL_4272c5fbe82346b4836954de3bddb4da"
            ],
            "layout": "IPY_MODEL_9677e65121954f258ef60324dc6622d7"
          }
        },
        "9d5bdaa13c5f4ebf8b4053183bc327d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fec1adaf97bf4d17bf257f86385ce31e",
            "placeholder": "​",
            "style": "IPY_MODEL_1dc89506337148b7b1b0ed7d59ea254d",
            "value": "Map: 100%"
          }
        },
        "7c0f438da24a40c98d15cf7aae3cd598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a5aad78e7e42fdb6a4737a741d50b9",
            "max": 198,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_083d3292cb124edd98470bf4fb42c58e",
            "value": 198
          }
        },
        "4272c5fbe82346b4836954de3bddb4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7efefd800a8a47bf96f988f167f43595",
            "placeholder": "​",
            "style": "IPY_MODEL_6666b2e33c8243e4be0c60e9daa05cec",
            "value": " 198/198 [00:00&lt;00:00, 778.12 examples/s]"
          }
        },
        "9677e65121954f258ef60324dc6622d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec1adaf97bf4d17bf257f86385ce31e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dc89506337148b7b1b0ed7d59ea254d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5a5aad78e7e42fdb6a4737a741d50b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083d3292cb124edd98470bf4fb42c58e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7efefd800a8a47bf96f988f167f43595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6666b2e33c8243e4be0c60e9daa05cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0be70dc7d224209a6b739bcd29135d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_659d9b45142a4e3f996d5c7203429193",
              "IPY_MODEL_9a14dbb008024defa38b16a568e4ab0b",
              "IPY_MODEL_e01a832d9d004dd8a108a5fd0800ee8a"
            ],
            "layout": "IPY_MODEL_e65e2108f9484274b5fcaa888313ce1d"
          }
        },
        "659d9b45142a4e3f996d5c7203429193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27369bb7606a4beeb2b19d88e9838579",
            "placeholder": "​",
            "style": "IPY_MODEL_711ffd6bc7a645e8a2dba35c0fffb069",
            "value": "Map: 100%"
          }
        },
        "9a14dbb008024defa38b16a568e4ab0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9800fc286ec4d50a30c92465c2176bc",
            "max": 69,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc58fa23ace74ef3a1d078b2e842870c",
            "value": 69
          }
        },
        "e01a832d9d004dd8a108a5fd0800ee8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8674428e3b5f4ac29a4ddcdb8b563df6",
            "placeholder": "​",
            "style": "IPY_MODEL_cbe4b97d3d5142caaf2e4e96d84fdbf9",
            "value": " 69/69 [00:00&lt;00:00, 488.00 examples/s]"
          }
        },
        "e65e2108f9484274b5fcaa888313ce1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27369bb7606a4beeb2b19d88e9838579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "711ffd6bc7a645e8a2dba35c0fffb069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9800fc286ec4d50a30c92465c2176bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc58fa23ace74ef3a1d078b2e842870c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8674428e3b5f4ac29a4ddcdb8b563df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe4b97d3d5142caaf2e4e96d84fdbf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Project : Story generator from event and character embedding to construct interactive story"
      ],
      "metadata": {
        "id": "SyYYOO-ydptC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "tQmu4l44u8Nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"theotimbarbier\"\n",
        "os.environ['KAGGLE_KEY'] = \"f42b2359b5cef90c532db13949cdabfb\"\n",
        "\n",
        "!kaggle datasets download -d ratthachat/writing-prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbUjYeECl3hX",
        "outputId": "5f2adf81-d368-4261-9a12-536def0e4bfa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.15 / client 1.6.14)\n",
            "Dataset URL: https://www.kaggle.com/datasets/ratthachat/writing-prompts\n",
            "License(s): other\n",
            "writing-prompts.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip writing-prompts.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGZ2Dn1imW_k",
        "outputId": "28d9142c-ec33-4fc8-e6cf-e553aedeffeb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  writing-prompts.zip\n",
            "replace writingPrompts/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install pyarrow\n",
        "!pip install datasets\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6lJMPf1eX9r",
        "outputId": "629dd7ee-f1de-4cf6-b1bc-14d168f5ed4d",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "import spacy\n",
        "from gensim.models import Word2Vec\n",
        "import gensim\n",
        "from nltk import translate as tr\n",
        "import random\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from datasets import Dataset\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fdUZqlbNmcT-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) data handling"
      ],
      "metadata": {
        "id": "BMkggI0UEF75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"writingPrompts/train.wp_target\") as f:\n",
        "  stories = f.readlines()"
      ],
      "metadata": {
        "id": "T1XcC-EpEFec"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"writingPrompts/train.wp_source\") as f:\n",
        "  prompts = f.readlines()"
      ],
      "metadata": {
        "id": "FjbaUKLiTBJ-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 150"
      ],
      "metadata": {
        "id": "Oxupc4BSu9V5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = random.sample(range(len(stories)), k=N)"
      ],
      "metadata": {
        "id": "DDwYOdz-qLNX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "handledStories = [stories[i] for i in indexes]\n",
        "handledPrompts = [prompts[i] for i in indexes]"
      ],
      "metadata": {
        "id": "4VJm1dXoWq1G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "handledPrompts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gv7XuOrEW3-C",
        "outputId": "d6121e97-c6b2-4f72-c04d-23d458226d50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[ WP ] Sunflowers are now sinflowers ; every time you commit one of the seven sins , a sinflower grows on your lawn . Your neighbor just moved in and their yard is full of these flowers . They invite you over for dinner .\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "handledStories[0]"
      ],
      "metadata": {
        "id": "zdwdd06VOzHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d98ae6e-d35b-4714-a292-91db29f6fb82"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"`` It 's for stealing , I bet , '' Susan said with a not-so-subtle nod to the yellow flowers waving in the breeze . `` I saw the movers carrying in a box full of toys , including a skateboard . I bet they have a little monster who will go around destroying the whole neighborhood . Graffiti , drugs… who knows ? '' She swirled her glass of lemonade with her straw ; even from here I could smell the pungent tang of whatever booze she 'd spiked it with . As Susan spoke , her eyes kept darting across the porch like she was afraid the new family might be watching and listening from all the way across the street . <newline> <newline> Carolyn disagreed . `` They 're perverts , '' she declared in the most certain tone despite having never even met any member of the family . `` Who knows what kind of sick things they 're doing in there ? *Normal* people do n't get a yard full of sinflowers within a week . It 's disgusting . What do you think , Connie ? '' <newline> <newline> I kept my mouth shut . It would have been so easy to point out that both of them kept a set of gardening shears in their front closet . Carolyn in particular seemed to have a compulsive need to 'trim the weeds ' in her yard as soon as her neighbor Paul came over for 'tea . ' `` It 's really none of our business , '' I said . `` I 'm sure we 'll learn more about them eventually . '' Hopefully that would end the conversation . But Carolyn and Susan traded a smirking look , and I knew that my efforts were futile . `` You know , '' I broke in before either of them could think of a retort , `` I just remembered , I 've got to work on Kara 's costume for the school play . '' I stood from the chair on Susan 's porch . `` Thank you for having me over . '' <newline> <newline> Susan and Carolyn said their goodbyes to me , complete with a phony `` oh , we *must* do this again sometime ! '' and exaggerated gushing over how we all did n't spend enough time together now that our kids were grown up and in school . It took all of my willpower to roll my eyes ; being neighbors was n't enough ? I already spent far too much time with them for my tastes . The second I left the porch , they 'd probably start bashing me behind my back too despite the fact that my lawn was sinflower-free *without* having to do constant pruning . <newline> <newline> I walked down the driveway and across the street . The hot asphalt baked in the hot sun , although the leafy elms swaying overhead were already beginning to change colors for fall . Quiet houses lined the street , and the only sound was a distant lawnmower whirring . It was your typical , quiet suburban neighborhood full of cookie-cutter houses and gossipy house wives . <newline> <newline> As I made it onto the opposite sidewalk , the front door of the new neighbor 's house slammed shut . A man walked down the steps toward the car in the driveway , but stopped in his tracks when we made eye contact . I 'd seen him moving in , but I had n't seen the rest of his family yet . I guess they were afraid to make their introductions with all of us able to see their flowers so openly . People like that tended to keep to themselves . But instead of going straight to his car , he approached me . <newline> <newline> “ I ’ m Alan , ” he said . At least six feet tall , he towered over me and had a firm handshake . His eyes were a soft brown , and his beard was neatly trimmed . He wore a suit and tie , looking perfectly respectable . <newline> <newline> “ Connie , ” I introduced myself with a grin . <newline> <newline> “ I ’ ve got to run , ” he said with true regret in his voice . “ Court date downtown ; I ’ m a patent attorney . But I ’ ve been meaning to invite you and your family over for dinner . Would you be free this evening ? ” <newline> <newline> Across the street , I could feel Susan and Carolyn ’ s eyes practically burning holes through my back . I ’ d no doubt receive a phone call as soon as I got inside , wanting to know *every* detail about the thieving perverts . Perhaps they would have added “ murderers ” to the list of accusations by then . <newline> <newline> “ That would be lovely , ” I answered . <newline> <newline> “ Great . We ’ ll see you at , say , seven ? ” <newline> <newline> -- -- -- -- -- - <newline> <newline> My family walked up the path toward the door , past the rows of sunflowers growing on the lawn . We all tried to pretend that they weren ’ t there . I smoothed my dress one last time , looked back at my husband and kids to make sure everyone was ready , then rang the doorbell . The faint sound of chimes drifted out from inside the house . <newline> <newline> Alan answered the door with a wide grin . A boy , roughly fourteen years with blue eyes and sandy hair , stood at his side and was introduced as his son . We all exchanged greetings , then Alan ushered us all into his beautifully-decorated and spotless home . But the most notable feature was that there were multiple vases in each room , each one full of bright yellow sinflowers . <newline> <newline> “ Why do you have *those* out ? ” Kara asked . She was old enough to know what they meant now , but not quite old enough to realize how offensive the question might be . <newline> <newline> “ Kara ! ” I hissed , but Alan just laughed . <newline> <newline> “ It ’ s all right. ” From down the hall , another man approached , also wearing a fine suit . He came and stood by Alan ’ s side , and the two exchanged a brief kiss . “ My partner and I are actually quite proud of them. ” <newline>\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We remove the useless terms"
      ],
      "metadata": {
        "id": "rg-torVFYcB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "termsToRemove = {\"<newline>\", \".\\n\", \"?\\n\", \"!\\n\", \"...\\n\", \"[ WP ]\"}"
      ],
      "metadata": {
        "id": "lPAaIzZCaSqo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processedStories = []\n",
        "for story in handledStories:\n",
        "  for term in termsToRemove:\n",
        "    story = story.replace(term, \"\")\n",
        "  processedStories.append(story)"
      ],
      "metadata": {
        "id": "XcXZkUE3ZSuG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processedPrompts = []\n",
        "for prompt in handledPrompts:\n",
        "  for term in termsToRemove:\n",
        "    prompt = prompt.replace(term, \"\")\n",
        "  processedPrompts.append(prompt)"
      ],
      "metadata": {
        "id": "oQRkCc9Tj1Vo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbTrain = int(0.8 * N)"
      ],
      "metadata": {
        "id": "XOkJ7jrYjybF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainProcessedPrompts = processedPrompts[:nbTrain]\n",
        "trainProcessedStories = processedStories[:nbTrain]"
      ],
      "metadata": {
        "id": "IX9O4PCajlDD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testProcessedPrompts = processedPrompts[nbTrain:]\n",
        "testProcessedStories = processedStories[nbTrain:]"
      ],
      "metadata": {
        "id": "SIO9leTStVRD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Event creation"
      ],
      "metadata": {
        "id": "HJKPgg5ud2H9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic event definition is define, as in paper *Event Representations for Automated Story Generation with Deep Neural Nets* : e = <s,v,o,m> with s the subject, v the verb, o the object and m an optional modifier."
      ],
      "metadata": {
        "id": "GU9RPyivqwg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we create an Event class :"
      ],
      "metadata": {
        "id": "j1OFsMKL2RsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Event:\n",
        "  def __init__(self, subject = None, verb = None, o = None, modifier = None):\n",
        "    self.subject = subject\n",
        "    self.verb = verb\n",
        "    self.obj = o\n",
        "    self.modifier = modifier\n",
        "\n",
        "  def toString(self):\n",
        "    return str(self.subject) + \", \" + str(self.verb) + \", \" + str(self.obj) + \", \" + str(self.modifier)\n",
        "\n",
        "  def toStringNoComa(self):\n",
        "    return str(self.subject) + \" \" + str(self.verb) + \" \" + str(self.obj) + \" \" + str(self.modifier)\n",
        "\n",
        "  def toList(self):\n",
        "    return [self.subject, self.verb, self.obj, self.modifier]\n"
      ],
      "metadata": {
        "id": "FlkfgV_t2SEf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we create a tokenizer which allow us to recover the part of speech of the tokens and the dependencies. We use spacy to do that."
      ],
      "metadata": {
        "id": "9eo95NpZraOk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_vrs37kidMe1"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "    return [x for x in nlp(text) if x.pos_ not in {'PUNCT', 'CCONJ', 'DET', 'SYM', 'X'}]"
      ],
      "metadata": {
        "id": "Wv9XTwlmptP0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in nlp(processedStories[0]).sents:\n",
        "  for token in sent:\n",
        "    print(token.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fAAxb3eqDAsJ",
        "outputId": "b0ea9eaf-c599-4ac5-d0b1-3a6c1670635e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'s\n",
            "'s\n",
            "'s\n",
            "said\n",
            "'s\n",
            "for\n",
            "stealing\n",
            "bet\n",
            "'s\n",
            "said\n",
            "said\n",
            "said\n",
            "said\n",
            "said\n",
            "nod\n",
            "subtle\n",
            "subtle\n",
            "subtle\n",
            "subtle\n",
            "nod\n",
            "with\n",
            "nod\n",
            "flowers\n",
            "flowers\n",
            "to\n",
            "flowers\n",
            "waving\n",
            "breeze\n",
            "in\n",
            "said\n",
            "saw\n",
            "saw\n",
            "saw\n",
            "saw\n",
            "movers\n",
            "carrying\n",
            "saw\n",
            "carrying\n",
            "box\n",
            "in\n",
            "box\n",
            "full\n",
            "of\n",
            "box\n",
            "box\n",
            "skateboard\n",
            "including\n",
            "saw\n",
            "bet\n",
            "bet\n",
            "have\n",
            "bet\n",
            "monster\n",
            "monster\n",
            "have\n",
            "go\n",
            "go\n",
            "monster\n",
            "go\n",
            "go\n",
            "neighborhood\n",
            "neighborhood\n",
            "destroying\n",
            "bet\n",
            "Graffiti\n",
            "Graffiti\n",
            "Graffiti\n",
            "Graffiti\n",
            "knows\n",
            "Graffiti\n",
            "Graffiti\n",
            "Graffiti\n",
            "swirled\n",
            "smell\n",
            "glass\n",
            "swirled\n",
            "glass\n",
            "of\n",
            "swirled\n",
            "straw\n",
            "with\n",
            "smell\n",
            "from\n",
            "smell\n",
            "from\n",
            "smell\n",
            "smell\n",
            "smell\n",
            "tang\n",
            "tang\n",
            "smell\n",
            "tang\n",
            "booze\n",
            "of\n",
            "spiked\n",
            "spiked\n",
            "tang\n",
            "spiked\n",
            "spiked\n",
            "smell\n",
            "spoke\n",
            "spoke\n",
            "kept\n",
            "kept\n",
            "eyes\n",
            "kept\n",
            "kept\n",
            "kept\n",
            "darting\n",
            "porch\n",
            "across\n",
            "was\n",
            "was\n",
            "darting\n",
            "was\n",
            "family\n",
            "family\n",
            "watching\n",
            "watching\n",
            "watching\n",
            "afraid\n",
            "watching\n",
            "watching\n",
            "listening\n",
            "way\n",
            "way\n",
            "across\n",
            "from\n",
            "street\n",
            "across\n",
            "kept\n",
            ".\n",
            "disagreed\n",
            "disagreed\n",
            "disagreed\n",
            "'re\n",
            "'re\n",
            "'re\n",
            "declared\n",
            "'re\n",
            "declared\n",
            "declared\n",
            "declared\n",
            "declared\n",
            "declared\n",
            "tone\n",
            "certain\n",
            "tone\n",
            "in\n",
            "declared\n",
            "met\n",
            "met\n",
            "met\n",
            "despite\n",
            "member\n",
            "met\n",
            "member\n",
            "family\n",
            "of\n",
            "declared\n",
            "knows\n",
            "knows\n",
            "knows\n",
            "knows\n",
            "kind\n",
            "knows\n",
            "kind\n",
            "things\n",
            "of\n",
            "doing\n",
            "doing\n",
            "things\n",
            "there\n",
            "doing\n",
            "knows\n",
            "get\n",
            "people\n",
            "people\n",
            "get\n",
            "get\n",
            "get\n",
            "get\n",
            "yard\n",
            "get\n",
            "yard\n",
            "full\n",
            "of\n",
            "get\n",
            "week\n",
            "within\n",
            "get\n",
            "'s\n",
            "'s\n",
            "'s\n",
            "'s\n",
            "think\n",
            "think\n",
            "think\n",
            "think\n",
            "think\n",
            "think\n",
            "think\n",
            "think\n",
            "''\n",
            "kept\n",
            "kept\n",
            "mouth\n",
            "kept\n",
            "kept\n",
            "kept\n",
            "been\n",
            "been\n",
            "been\n",
            "been\n",
            "easy\n",
            "been\n",
            "point\n",
            "easy\n",
            "point\n",
            "kept\n",
            "kept\n",
            "both\n",
            "of\n",
            "point\n",
            "set\n",
            "kept\n",
            "set\n",
            "shears\n",
            "of\n",
            "kept\n",
            "closet\n",
            "closet\n",
            "in\n",
            "been\n",
            "seemed\n",
            "Carolyn\n",
            "in\n",
            "seemed\n",
            "have\n",
            "seemed\n",
            "need\n",
            "need\n",
            "have\n",
            "trim\n",
            "trim\n",
            "need\n",
            "weeds\n",
            "trim\n",
            "trim\n",
            "trim\n",
            "yard\n",
            "in\n",
            "soon\n",
            "trim\n",
            "came\n",
            "neighbor\n",
            "came\n",
            "neighbor\n",
            "soon\n",
            "came\n",
            "came\n",
            "for\n",
            "for\n",
            "seemed\n",
            "seemed\n",
            "'s\n",
            "'s\n",
            "'s\n",
            "said\n",
            "'s\n",
            "'s\n",
            "none\n",
            "business\n",
            "of\n",
            "said\n",
            "said\n",
            "said\n",
            "said\n",
            "said\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "m\n",
            "learn\n",
            "learn\n",
            "sure\n",
            "learn\n",
            "more\n",
            "about\n",
            "learn\n",
            "I\n",
            "I\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "conversation\n",
            "end\n",
            "end\n",
            "traded\n",
            "traded\n",
            "Carolyn\n",
            "Carolyn\n",
            "traded\n",
            "look\n",
            "look\n",
            "traded\n",
            "traded\n",
            "traded\n",
            "knew\n",
            "traded\n",
            "were\n",
            "efforts\n",
            "were\n",
            "knew\n",
            "were\n",
            "knew\n",
            "know\n",
            "know\n",
            "know\n",
            "broke\n",
            "broke\n",
            "broke\n",
            "broke\n",
            "broke\n",
            "broke\n",
            "think\n",
            "think\n",
            "either\n",
            "of\n",
            "think\n",
            "broke\n",
            "think\n",
            "retort\n",
            "of\n",
            "think\n",
            "think\n",
            "think\n",
            "remembered\n",
            "remembered\n",
            "think\n",
            "got\n",
            "got\n",
            "got\n",
            "got\n",
            "remembered\n",
            "work\n",
            "got\n",
            "work\n",
            "costume\n",
            "Kara\n",
            "on\n",
            "costume\n",
            "play\n",
            "play\n",
            "for\n",
            "broke\n",
            "broke\n",
            "stood\n",
            "stood\n",
            "stood\n",
            "chair\n",
            "from\n",
            "stood\n",
            "porch\n",
            "Susan\n",
            "on\n",
            "stood\n",
            "Thank\n",
            "Thank\n",
            "Thank\n",
            "Thank\n",
            "Thank\n",
            "for\n",
            "having\n",
            "having\n",
            "Thank\n",
            "Thank\n",
            "''\n",
            "said\n",
            "Susan\n",
            "Susan\n",
            "said\n",
            "goodbyes\n",
            "said\n",
            "said\n",
            "to\n",
            "said\n",
            "said\n",
            "complete\n",
            "phony\n",
            "with\n",
            "we\n",
            "we\n",
            "we\n",
            "we\n",
            "do\n",
            "we\n",
            "do\n",
            "do\n",
            "said\n",
            "do\n",
            "do\n",
            "do\n",
            "said\n",
            "said\n",
            "exaggerated\n",
            "exaggerated\n",
            "exaggerated\n",
            "gushing\n",
            "spend\n",
            "spend\n",
            "we\n",
            "spend\n",
            "spend\n",
            "exaggerated\n",
            "time\n",
            "spend\n",
            "spend\n",
            "spend\n",
            "grown\n",
            "kids\n",
            "grown\n",
            "grown\n",
            "spend\n",
            "grown\n",
            "up\n",
            "up\n",
            "in\n",
            "exaggerated\n",
            "took\n",
            "was\n",
            "took\n",
            "all\n",
            "willpower\n",
            "of\n",
            "roll\n",
            "took\n",
            "eyes\n",
            "roll\n",
            "was\n",
            "was\n",
            "being\n",
            "was\n",
            "was\n",
            "was\n",
            "was\n",
            "spent\n",
            "spent\n",
            "spent\n",
            "much\n",
            "much\n",
            "time\n",
            "spent\n",
            "spent\n",
            "with\n",
            "spent\n",
            "tastes\n",
            "for\n",
            "spent\n",
            "second\n",
            "start\n",
            "left\n",
            "second\n",
            "porch\n",
            "left\n",
            "start\n",
            "start\n",
            "start\n",
            "start\n",
            "start\n",
            "start\n",
            "bashing\n",
            "bashing\n",
            "back\n",
            "behind\n",
            "bashing\n",
            "bashing\n",
            "fact\n",
            "despite\n",
            "was\n",
            "lawn\n",
            "was\n",
            "fact\n",
            "free\n",
            "free\n",
            "was\n",
            "was\n",
            "was\n",
            "without\n",
            "without\n",
            "do\n",
            "having\n",
            "pruning\n",
            "do\n",
            "start\n",
            ".\n",
            "walked\n",
            "walked\n",
            "walked\n",
            "driveway\n",
            "down\n",
            "down\n",
            "down\n",
            "street\n",
            "across\n",
            "walked\n",
            "asphalt\n",
            "asphalt\n",
            "asphalt\n",
            "asphalt\n",
            "baked\n",
            "sun\n",
            "sun\n",
            "in\n",
            "asphalt\n",
            "beginning\n",
            "elms\n",
            "elms\n",
            "beginning\n",
            "elms\n",
            "swaying\n",
            "beginning\n",
            "beginning\n",
            "asphalt\n",
            "change\n",
            "beginning\n",
            "change\n",
            "change\n",
            "for\n",
            "asphalt\n",
            "houses\n",
            "lined\n",
            "lined\n",
            "street\n",
            "lined\n",
            "lined\n",
            "lined\n",
            "sound\n",
            "sound\n",
            "was\n",
            "lined\n",
            "whirring\n",
            "whirring\n",
            "whirring\n",
            "was\n",
            "was\n",
            "was\n",
            "was\n",
            "neighborhood\n",
            "neighborhood\n",
            "neighborhood\n",
            "neighborhood\n",
            "neighborhood\n",
            "was\n",
            "neighborhood\n",
            "full\n",
            "cutter\n",
            "cutter\n",
            "houses\n",
            "of\n",
            "houses\n",
            "wives\n",
            "wives\n",
            "houses\n",
            "was\n",
            ".\n",
            "made\n",
            "made\n",
            "slammed\n",
            "made\n",
            "made\n",
            "sidewalk\n",
            "sidewalk\n",
            "onto\n",
            "slammed\n",
            "door\n",
            "door\n",
            "slammed\n",
            "door\n",
            "neighbor\n",
            "neighbor\n",
            "house\n",
            "neighbor\n",
            "of\n",
            "slammed\n",
            "slammed\n",
            "slammed\n",
            "man\n",
            "walked\n",
            "walked\n",
            "walked\n",
            "steps\n",
            "down\n",
            "steps\n",
            "car\n",
            "toward\n",
            "car\n",
            "driveway\n",
            "in\n",
            "walked\n",
            "walked\n",
            "walked\n",
            "stopped\n",
            "tracks\n",
            "in\n",
            "made\n",
            "made\n",
            "stopped\n",
            "contact\n",
            "made\n",
            "walked\n",
            "seen\n",
            "seen\n",
            "seen\n",
            "moving\n",
            "seen\n",
            "moving\n",
            "seen\n",
            "seen\n",
            "seen\n",
            "seen\n",
            "seen\n",
            "seen\n",
            "rest\n",
            "seen\n",
            "rest\n",
            "family\n",
            "of\n",
            "seen\n",
            "seen\n",
            "guess\n",
            "guess\n",
            "were\n",
            "guess\n",
            "were\n",
            "make\n",
            "afraid\n",
            "introductions\n",
            "able\n",
            "introductions\n",
            "with\n",
            "all\n",
            "of\n",
            "make\n",
            "see\n",
            "able\n",
            "flowers\n",
            "see\n",
            "openly\n",
            "see\n",
            "guess\n",
            "tended\n",
            "People\n",
            "like\n",
            "tended\n",
            "keep\n",
            "tended\n",
            "keep\n",
            "to\n",
            "tended\n",
            "approached\n",
            "of\n",
            "approached\n",
            "of\n",
            "to\n",
            "going\n",
            "car\n",
            "to\n",
            "approached\n",
            "approached\n",
            "approached\n",
            "approached\n",
            "approached\n",
            ".\n",
            "I\n",
            "said\n",
            "I\n",
            "I\n",
            "I\n",
            "said\n",
            "said\n",
            "said\n",
            "said\n",
            "said\n",
            "least\n",
            "six\n",
            "feet\n",
            "tall\n",
            "towered\n",
            "towered\n",
            "towered\n",
            "towered\n",
            "towered\n",
            "over\n",
            "towered\n",
            "towered\n",
            "handshake\n",
            "handshake\n",
            "had\n",
            "towered\n",
            "eyes\n",
            "were\n",
            "were\n",
            "brown\n",
            "brown\n",
            "were\n",
            "were\n",
            "were\n",
            "beard\n",
            "trimmed\n",
            "trimmed\n",
            "trimmed\n",
            "were\n",
            "trimmed\n",
            "wore\n",
            "wore\n",
            "suit\n",
            "wore\n",
            "suit\n",
            "suit\n",
            "wore\n",
            "wore\n",
            "respectable\n",
            "looking\n",
            "wore\n",
            ".\n",
            "introduced\n",
            "introduced\n",
            "introduced\n",
            "introduced\n",
            "introduced\n",
            "introduced\n",
            "introduced\n",
            "introduced\n",
            "grin\n",
            "with\n",
            "introduced\n",
            ".\n",
            "said\n",
            "got\n",
            "got\n",
            "got\n",
            "said\n",
            "run\n",
            "got\n",
            "said\n",
            "said\n",
            "said\n",
            "said\n",
            "said\n",
            "regret\n",
            "with\n",
            "regret\n",
            "voice\n",
            "in\n",
            "said\n",
            "m\n",
            "date\n",
            "downtown\n",
            "m\n",
            "m\n",
            "m\n",
            "I\n",
            "m\n",
            "attorney\n",
            "attorney\n",
            "m\n",
            "m\n",
            "meaning\n",
            "meaning\n",
            "meaning\n",
            "been\n",
            "meaning\n",
            "meaning\n",
            "invite\n",
            "meaning\n",
            "invite\n",
            "you\n",
            "family\n",
            "you\n",
            "invite\n",
            "invite\n",
            "for\n",
            "meaning\n",
            "be\n",
            "be\n",
            "be\n",
            "be\n",
            "evening\n",
            "be\n",
            "be\n",
            "be\n",
            "”\n",
            "feel\n",
            "street\n",
            "Across\n",
            "feel\n",
            "feel\n",
            "feel\n",
            "feel\n",
            "eyes\n",
            "Susan\n",
            "Susan\n",
            "Susan\n",
            "Susan\n",
            "burning\n",
            "burning\n",
            "feel\n",
            "burning\n",
            "burning\n",
            "back\n",
            "through\n",
            "feel\n",
            "I\n",
            "I\n",
            "receive\n",
            "doubt\n",
            "receive\n",
            "receive\n",
            "call\n",
            "call\n",
            "receive\n",
            "soon\n",
            "receive\n",
            "got\n",
            "got\n",
            "soon\n",
            "got\n",
            "receive\n",
            "receive\n",
            "know\n",
            "wanting\n",
            "know\n",
            "detail\n",
            "detail\n",
            "know\n",
            "detail\n",
            "perverts\n",
            "perverts\n",
            "about\n",
            "receive\n",
            "added\n",
            "added\n",
            "added\n",
            "added\n",
            "added\n",
            "murderers\n",
            "added\n",
            "murderers\n",
            "added\n",
            "list\n",
            "to\n",
            "list\n",
            "of\n",
            "added\n",
            "by\n",
            "added\n",
            ".\n",
            "answered\n",
            "be\n",
            "be\n",
            "answered\n",
            "be\n",
            "answered\n",
            "answered\n",
            "answered\n",
            "answered\n",
            "answered\n",
            ".\n",
            "Great\n",
            "Great\n",
            "Great\n",
            "see\n",
            "see\n",
            "see\n",
            "see\n",
            "see\n",
            "see\n",
            "at\n",
            "at\n",
            "at\n",
            "see\n",
            "see\n",
            "see\n",
            "”\n",
            "see\n",
            "see\n",
            "see\n",
            "see\n",
            "see\n",
            "see\n",
            "-\n",
            "family\n",
            "walked\n",
            "see\n",
            "walked\n",
            "path\n",
            "up\n",
            "walked\n",
            "door\n",
            "toward\n",
            "walked\n",
            "walked\n",
            "rows\n",
            "past\n",
            "rows\n",
            "of\n",
            "sunflowers\n",
            "growing\n",
            "lawn\n",
            "on\n",
            "walked\n",
            "tried\n",
            "We\n",
            "tried\n",
            "pretend\n",
            "tried\n",
            "weren\n",
            "weren\n",
            "pretend\n",
            "weren\n",
            "weren\n",
            "t\n",
            "tried\n",
            "smoothed\n",
            "smoothed\n",
            "dress\n",
            "smoothed\n",
            "smoothed\n",
            "time\n",
            "smoothed\n",
            "smoothed\n",
            "smoothed\n",
            "looked\n",
            "looked\n",
            "husband\n",
            "at\n",
            "husband\n",
            "husband\n",
            "make\n",
            "looked\n",
            "make\n",
            "was\n",
            "sure\n",
            "was\n",
            "smoothed\n",
            "rang\n",
            "smoothed\n",
            "doorbell\n",
            "rang\n",
            "smoothed\n",
            "sound\n",
            "sound\n",
            "drifted\n",
            "sound\n",
            "of\n",
            "drifted\n",
            "drifted\n",
            "drifted\n",
            "from\n",
            "house\n",
            "inside\n",
            "drifted\n",
            ".\n",
            "answered\n",
            "answered\n",
            "door\n",
            "answered\n",
            "answered\n",
            "grin\n",
            "grin\n",
            "with\n",
            "answered\n",
            "boy\n",
            "stood\n",
            "boy\n",
            "fourteen\n",
            "years\n",
            "boy\n",
            "years\n",
            "eyes\n",
            "with\n",
            "eyes\n",
            "hair\n",
            "eyes\n",
            "stood\n",
            "stood\n",
            "stood\n",
            "side\n",
            "at\n",
            "stood\n",
            "introduced\n",
            "stood\n",
            "introduced\n",
            "son\n",
            "as\n",
            "stood\n",
            "exchanged\n",
            "We\n",
            "ushered\n",
            "exchanged\n",
            "ushered\n",
            "ushered\n",
            "ushered\n",
            "ushered\n",
            "ushered\n",
            "us\n",
            "ushered\n",
            "home\n",
            "decorated\n",
            "decorated\n",
            "home\n",
            "decorated\n",
            "decorated\n",
            "into\n",
            "ushered\n",
            "was\n",
            "feature\n",
            "notable\n",
            "feature\n",
            "was\n",
            "was\n",
            "were\n",
            "were\n",
            "was\n",
            "vases\n",
            "were\n",
            "vases\n",
            "room\n",
            "in\n",
            "vases\n",
            "one\n",
            "were\n",
            "one\n",
            "full\n",
            "yellow\n",
            "sinflowers\n",
            "of\n",
            "was\n",
            ".\n",
            "have\n",
            "have\n",
            "have\n",
            "have\n",
            "have\n",
            "have\n",
            "have\n",
            "have\n",
            "have\n",
            "have\n",
            "have\n",
            "asked\n",
            "asked\n",
            "asked\n",
            "was\n",
            "was\n",
            "was\n",
            "old\n",
            "know\n",
            "old\n",
            "meant\n",
            "meant\n",
            "know\n",
            "meant\n",
            "know\n",
            "was\n",
            "old\n",
            "old\n",
            "was\n",
            "old\n",
            "realize\n",
            "old\n",
            "offensive\n",
            "be\n",
            "question\n",
            "be\n",
            "be\n",
            "realize\n",
            "was\n",
            ".\n",
            "Kara\n",
            "Kara\n",
            "Kara\n",
            "Kara\n",
            "hissed\n",
            "hissed\n",
            "hissed\n",
            "hissed\n",
            "laughed\n",
            "laughed\n",
            "hissed\n",
            "laughed\n",
            ".\n",
            "s\n",
            "s\n",
            "s\n",
            "s\n",
            "right\n",
            "s\n",
            "s\n",
            "s\n",
            "approached\n",
            "From\n",
            "hall\n",
            "down\n",
            "approached\n",
            "man\n",
            "approached\n",
            "approached\n",
            "approached\n",
            "wearing\n",
            "approached\n",
            "suit\n",
            "suit\n",
            "wearing\n",
            "approached\n",
            "came\n",
            "came\n",
            "came\n",
            "came\n",
            "stood\n",
            "side\n",
            "s\n",
            "Alan\n",
            "by\n",
            "came\n",
            "came\n",
            "two\n",
            "exchanged\n",
            "came\n",
            "kiss\n",
            "kiss\n",
            "exchanged\n",
            "exchanged\n",
            "are\n",
            "partner\n",
            "are\n",
            "partner\n",
            "partner\n",
            "are\n",
            "are\n",
            "proud\n",
            "are\n",
            "proud\n",
            "of\n",
            "are\n",
            "are\n",
            "”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of possible subject, dependencies, verbs, and modifier in spacy that are intesting for our purpose"
      ],
      "metadata": {
        "id": "3CB5Z1v_10Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjTypes = (\"nsubj\", \"csubj\", \"nsubjpass\", \"csubjpass\")"
      ],
      "metadata": {
        "id": "UqibQNhv1073"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verbTypes = {\"AUX\", \"VERB\"}"
      ],
      "metadata": {
        "id": "BZHzzoQ_790x"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objTypes = {\"dobj\", \"attr\"}"
      ],
      "metadata": {
        "id": "z6sDRDgp8z_U"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modTypes = {\"iobj\", \"pobj\", \"ccomp\", \"xcomp\", \"amod\",\"nmod\", \"npmod\", \"advcl\"}"
      ],
      "metadata": {
        "id": "e9GYKyIEAj0r"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def searchVerbsDependencies(verb, verbList):\n",
        "  objects = []\n",
        "  modifier = []\n",
        "  for t in verb.children:\n",
        "    if not(t.pos_ in verbTypes):\n",
        "      if (t.dep_ in objTypes):\n",
        "        objects.append(t)\n",
        "      if t.dep_ in modTypes:\n",
        "        modifier.append(t)\n",
        "    else:\n",
        "      searchVerbsDependencies(t, verbList)\n",
        "  verbList.append([verb, objects, modifier])\n",
        "  return verbList"
      ],
      "metadata": {
        "id": "Ar7UKVjxmIo-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eventCreator(story):\n",
        "  event2Sent = {}\n",
        "  totalEventList = []\n",
        "  for sent in nlp(story).sents:\n",
        "    eventList = []\n",
        "    for token in sent:\n",
        "      #create an event from a subject\n",
        "      if token.dep_ in subjTypes:\n",
        "        subj = token\n",
        "        verb = subj.head\n",
        "        if verb.pos_ in verbTypes:\n",
        "          verbList = []\n",
        "          verbList = searchVerbsDependencies(verb, verbList)\n",
        "\n",
        "          for v in verbList:\n",
        "            if len(v[1]) == 0:\n",
        "              for m in v[2]:\n",
        "                eventList.append(Event(subj.lemma_, v[0].lemma_, \"NoObject\", m.lemma_))\n",
        "            elif len(v[2]) == 0:\n",
        "              for o in v[1]:\n",
        "                eventList.append(Event(subj.lemma_, v[0].lemma_, o.lemma_, \"NoObject\"))\n",
        "            else:\n",
        "              for o in v[1]:\n",
        "                for m in v[2]:\n",
        "                  eventList.append(Event(subj.lemma_, v[0].lemma_, o.lemma_, m.lemma_))\n",
        "      for event in eventList:\n",
        "        event2Sent[event] = sent.text\n",
        "    totalEventList += eventList\n",
        "  return event2Sent, totalEventList\n"
      ],
      "metadata": {
        "id": "mCxULT3psgDv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processedPrompts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HEAxlL3Xjruk",
        "outputId": "95187fad-90a6-408c-ffc0-2913157dbd08"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sunflowers are now sinflowers ; every time you commit one of the seven sins , a sinflower grows on your lawn . Your neighbor just moved in and their yard is full of these flowers . They invite you over for dinner '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "event2Sent, eventList = eventCreator(processedStories[0])"
      ],
      "metadata": {
        "id": "lSbHxqvu242d"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in eventList:\n",
        "  print(event.toList())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJM7vb8q27Q_",
        "outputId": "1c661f6c-e4ff-4399-ffbe-d3f33ebaccb8",
        "collapsed": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'have', 'monster', 'NoObject']\n",
            "['they', 'have', 'monster', 'NoObject']\n",
            "['who', 'destroy', 'neighborhood', 'NoObject']\n",
            "['she', 'swirl', 'glass', 'NoObject']\n",
            "['I', 'swirl', 'glass', 'NoObject']\n",
            "['I', 'smell', 'tang', 'NoObject']\n",
            "['she', 'spike', 'it', 'NoObject']\n",
            "['they', 'be', 'pervert', 'NoObject']\n",
            "['she', 'be', 'pervert', 'NoObject']\n",
            "['who', 'know', 'NoObject', 'kind']\n",
            "['people', 'get', 'yard', 'NoObject']\n",
            "['you', 'think', 'what', 'NoObject']\n",
            "['I', 'keep', 'mouth', 'NoObject']\n",
            "['both', 'keep', 'set', 'NoObject']\n",
            "['Carolyn', 'have', 'need', 'NoObject']\n",
            "['it', 'be', 'none', 'NoObject']\n",
            "['I', 'be', 'none', 'NoObject']\n",
            "['we', 'learn', 'more', 'NoObject']\n",
            "['that', 'end', 'conversation', 'NoObject']\n",
            "['Carolyn', 'trade', 'look', 'NoObject']\n",
            "['Susan', 'do', 'this', 'NoObject']\n",
            "['Susan', 'say', 'goodbyes', 'complete']\n",
            "['we', 'do', 'this', 'NoObject']\n",
            "['we', 'spend', 'time', 'NoObject']\n",
            "['it', 'roll', 'eye', 'NoObject']\n",
            "['it', 'take', 'all', 'NoObject']\n",
            "['be', 'roll', 'eye', 'NoObject']\n",
            "['be', 'take', 'all', 'NoObject']\n",
            "['be', 'be', 'neighbor', 'NoObject']\n",
            "['I', 'spend', 'time', 'NoObject']\n",
            "['I', 'leave', 'porch', 'NoObject']\n",
            "['they', 'bash', 'I', 'NoObject']\n",
            "['elm', 'change', 'color', 'NoObject']\n",
            "['house', 'be', 'whirring', 'NoObject']\n",
            "['house', 'line', 'street', 'NoObject']\n",
            "['sound', 'be', 'whirring', 'NoObject']\n",
            "['it', 'be', 'neighborhood', 'NoObject']\n",
            "['I', 'make', 'it', 'NoObject']\n",
            "['door', 'make', 'it', 'NoObject']\n",
            "['man', 'make', 'contact', 'NoObject']\n",
            "['we', 'make', 'contact', 'NoObject']\n",
            "['I', 'see', 'rest', 'NoObject']\n",
            "['I', 'see', 'rest', 'NoObject']\n",
            "['he', 'approach', 'I', 'NoObject']\n",
            "['he', 'say', 'NoObject', 'I']\n",
            "['he', 'have', 'handshake', 'NoObject']\n",
            "['he', 'tower', 'NoObject', 'tall']\n",
            "['eye', 'be', 'brown', 'NoObject']\n",
            "['he', 'wear', 'suit', 'NoObject']\n",
            "['I', 'introduce', 'myself', 'NoObject']\n",
            "['I', 'm', 'attorney', 'downtown']\n",
            "['I', 'invite', 'you', 'NoObject']\n",
            "['I', 'burn', 'hole', 'NoObject']\n",
            "['eye', 'burn', 'hole', 'NoObject']\n",
            "['they', 'add', 'murderer', 'NoObject']\n",
            "['we', 'see', 'you', 'NoObject']\n",
            "['we', 'see', 'seven', 'NoObject']\n",
            "['we', 'weren', 't', 'NoObject']\n",
            "['they', 'weren', 't', 'NoObject']\n",
            "['I', 'ring', 'doorbell', 'NoObject']\n",
            "['I', 'smooth', 'dress', 'NoObject']\n",
            "['Alan', 'answer', 'door', 'NoObject']\n",
            "['we', 'exchange', 'greeting', 'NoObject']\n",
            "['Alan', 'exchange', 'greeting', 'NoObject']\n",
            "['Alan', 'usher', 'we', 'NoObject']\n",
            "['feature', 'be', 'vase', 'NoObject']\n",
            "['feature', 'be', 'one', 'NoObject']\n",
            "['you', 'have', '*', 'NoObject']\n",
            "['you', 'have', 'those', 'NoObject']\n",
            "['they', 'mean', 'what', 'NoObject']\n",
            "['man', 'wear', 'suit', 'NoObject']\n",
            "['he', 'exchange', 'kiss', 'NoObject']\n",
            "['two', 'exchange', 'kiss', 'NoObject']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create all the event in our story and prompts"
      ],
      "metadata": {
        "id": "kHU5WhnycTnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createEventsFromPrompts(prompts):\n",
        "  promptEvents = []\n",
        "  promptEvent2Sent = {}\n",
        "  for prompt in prompts:\n",
        "    eventDict, eventList = eventCreator(prompt)\n",
        "    promptEvents.append(eventList)\n",
        "    promptEvent2Sent.update(eventDict)\n",
        "  return promptEvent2Sent, promptEvents\n",
        "\n",
        "def createEventsFromStories(stories):\n",
        "  storiesEvents = []\n",
        "  storiesEvent2Sent = {}\n",
        "  for story in stories:\n",
        "    eventDict, eventList = eventCreator(story)\n",
        "    storiesEvents.append(eventList)\n",
        "    storiesEvent2Sent.update(eventDict)\n",
        "  return storiesEvent2Sent, storiesEvents"
      ],
      "metadata": {
        "id": "Pp7K-J6dJLLZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPromptEvent2Sent, trainPromptsEvents = createEventsFromPrompts(trainProcessedPrompts)\n",
        "trainStoriesEvent2Sent, trainStoriesEvents = createEventsFromStories(trainProcessedStories)"
      ],
      "metadata": {
        "id": "5RDYVRGWdreA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(trainPromptsEvents[10][1].toString())"
      ],
      "metadata": {
        "id": "4Mjm-APtjRFE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb = 0\n",
        "for events in trainPromptsEvents:\n",
        "  nb += len(events)\n",
        "print(nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ascbpzNteHhx",
        "outputId": "fa3907c7-7880-44c5-e1a0-9b5e00a4a81f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb = 0\n",
        "for events in trainStoriesEvents:\n",
        "  nb += len(events)\n",
        "print(nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcIRZW-FewAD",
        "outputId": "9cf891de-73a8-43f7-f90e-ccadf4a7eb3b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testPromptEvent2Sent, testPromptsEvents = createEventsFromPrompts(testProcessedPrompts)\n",
        "testStoriesEvent2Sent, testStoriesEvents = createEventsFromStories(testProcessedStories)"
      ],
      "metadata": {
        "id": "GRgzCgJLtgie"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Character Embedding"
      ],
      "metadata": {
        "id": "oMbXpzbJrTXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the name entity recognition to find character and we consider the related verbs and adjectives to this character as in work : *A Character-Centric Neural Model for Automated Story Generation*"
      ],
      "metadata": {
        "id": "SjXnBs0Svpdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processedStories[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iEJZXDiF5Ahm",
        "outputId": "198422d7-c440-4d12-e20f-43d27bcd9b84"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"`` It 's for stealing , I bet , '' Susan said with a not-so-subtle nod to the yellow flowers waving in the breeze . `` I saw the movers carrying in a box full of toys , including a skateboard . I bet they have a little monster who will go around destroying the whole neighborhood . Graffiti , drugs… who knows ? '' She swirled her glass of lemonade with her straw ; even from here I could smell the pungent tang of whatever booze she 'd spiked it with . As Susan spoke , her eyes kept darting across the porch like she was afraid the new family might be watching and listening from all the way across the street .   Carolyn disagreed . `` They 're perverts , '' she declared in the most certain tone despite having never even met any member of the family . `` Who knows what kind of sick things they 're doing in there ? *Normal* people do n't get a yard full of sinflowers within a week . It 's disgusting . What do you think , Connie ? ''   I kept my mouth shut . It would have been so easy to point out that both of them kept a set of gardening shears in their front closet . Carolyn in particular seemed to have a compulsive need to 'trim the weeds ' in her yard as soon as her neighbor Paul came over for 'tea . ' `` It 's really none of our business , '' I said . `` I 'm sure we 'll learn more about them eventually . '' Hopefully that would end the conversation . But Carolyn and Susan traded a smirking look , and I knew that my efforts were futile . `` You know , '' I broke in before either of them could think of a retort , `` I just remembered , I 've got to work on Kara 's costume for the school play . '' I stood from the chair on Susan 's porch . `` Thank you for having me over . ''   Susan and Carolyn said their goodbyes to me , complete with a phony `` oh , we *must* do this again sometime ! '' and exaggerated gushing over how we all did n't spend enough time together now that our kids were grown up and in school . It took all of my willpower to roll my eyes ; being neighbors was n't enough ? I already spent far too much time with them for my tastes . The second I left the porch , they 'd probably start bashing me behind my back too despite the fact that my lawn was sinflower-free *without* having to do constant pruning .   I walked down the driveway and across the street . The hot asphalt baked in the hot sun , although the leafy elms swaying overhead were already beginning to change colors for fall . Quiet houses lined the street , and the only sound was a distant lawnmower whirring . It was your typical , quiet suburban neighborhood full of cookie-cutter houses and gossipy house wives .   As I made it onto the opposite sidewalk , the front door of the new neighbor 's house slammed shut . A man walked down the steps toward the car in the driveway , but stopped in his tracks when we made eye contact . I 'd seen him moving in , but I had n't seen the rest of his family yet . I guess they were afraid to make their introductions with all of us able to see their flowers so openly . People like that tended to keep to themselves . But instead of going straight to his car , he approached me .   “ I ’ m Alan , ” he said . At least six feet tall , he towered over me and had a firm handshake . His eyes were a soft brown , and his beard was neatly trimmed . He wore a suit and tie , looking perfectly respectable .   “ Connie , ” I introduced myself with a grin .   “ I ’ ve got to run , ” he said with true regret in his voice . “ Court date downtown ; I ’ m a patent attorney . But I ’ ve been meaning to invite you and your family over for dinner . Would you be free this evening ? ”   Across the street , I could feel Susan and Carolyn ’ s eyes practically burning holes through my back . I ’ d no doubt receive a phone call as soon as I got inside , wanting to know *every* detail about the thieving perverts . Perhaps they would have added “ murderers ” to the list of accusations by then .   “ That would be lovely , ” I answered .   “ Great . We ’ ll see you at , say , seven ? ”   -- -- -- -- -- -   My family walked up the path toward the door , past the rows of sunflowers growing on the lawn . We all tried to pretend that they weren ’ t there . I smoothed my dress one last time , looked back at my husband and kids to make sure everyone was ready , then rang the doorbell . The faint sound of chimes drifted out from inside the house .   Alan answered the door with a wide grin . A boy , roughly fourteen years with blue eyes and sandy hair , stood at his side and was introduced as his son . We all exchanged greetings , then Alan ushered us all into his beautifully-decorated and spotless home . But the most notable feature was that there were multiple vases in each room , each one full of bright yellow sinflowers .   “ Why do you have *those* out ? ” Kara asked . She was old enough to know what they meant now , but not quite old enough to realize how offensive the question might be .   “ Kara ! ” I hissed , but Alan just laughed .   “ It ’ s all right. ” From down the hall , another man approached , also wearing a fine suit . He came and stood by Alan ’ s side , and the two exchanged a brief kiss . “ My partner and I are actually quite proud of them. ” \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = tokenizer(processedStories[0])"
      ],
      "metadata": {
        "id": "K_QHL0g5rWCS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entityToRemove = {'O'}\n",
        "entityTypeToRemove = {'DATE', 'CARDINAL', 'ORDINAL', 'TIME'}"
      ],
      "metadata": {
        "id": "8kqVO3y4whwB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in sent:\n",
        "  if (not(token.ent_iob_ in entityToRemove)) and (not(token.ent_type_ in entityTypeToRemove)):\n",
        "    print(token.ent_iob_)\n",
        "    print(token.ent_type_)\n",
        "    print(token)"
      ],
      "metadata": {
        "id": "FDKTruQcuNzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91ee2f2-34a8-4ea9-8201-3eb959d5a496"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B\n",
            "PERSON\n",
            "Susan\n",
            "B\n",
            "PERSON\n",
            "Graffiti\n",
            "B\n",
            "PERSON\n",
            "Susan\n",
            "B\n",
            "PERSON\n",
            "Carolyn\n",
            "B\n",
            "PERSON\n",
            "Connie\n",
            "B\n",
            "PERSON\n",
            "Carolyn\n",
            "B\n",
            "PERSON\n",
            "Paul\n",
            "B\n",
            "PERSON\n",
            "Carolyn\n",
            "B\n",
            "PERSON\n",
            "Susan\n",
            "B\n",
            "PERSON\n",
            "Kara\n",
            "B\n",
            "PERSON\n",
            "Susan\n",
            "B\n",
            "PERSON\n",
            "Susan\n",
            "B\n",
            "PERSON\n",
            "Carolyn\n",
            "B\n",
            "PERSON\n",
            "Alan\n",
            "B\n",
            "QUANTITY\n",
            "At\n",
            "I\n",
            "QUANTITY\n",
            "least\n",
            "I\n",
            "QUANTITY\n",
            "six\n",
            "I\n",
            "QUANTITY\n",
            "feet\n",
            "B\n",
            "PERSON\n",
            "Connie\n",
            "B\n",
            "PERSON\n",
            "Susan\n",
            "B\n",
            "PERSON\n",
            "Carolyn\n",
            "I\n",
            "PERSON\n",
            "s\n",
            "B\n",
            "PERSON\n",
            "Alan\n",
            "B\n",
            "PERSON\n",
            "Alan\n",
            "B\n",
            "PERSON\n",
            "Kara\n",
            "B\n",
            "PERSON\n",
            "Kara\n",
            "B\n",
            "PERSON\n",
            "Alan\n",
            "B\n",
            "PERSON\n",
            "Alan\n",
            "I\n",
            "PERSON\n",
            "s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getCharacterEmbedding(corpus):\n",
        "  characterSet = set()\n",
        "  for text in corpus:\n",
        "    tokens = tokenizer(text)\n",
        "    #search for characters with spacy ner\n",
        "    for token in tokens:\n",
        "      if (not(token.ent_iob_ in entityToRemove)) and (not(token.ent_type_ in entityTypeToRemove)):\n",
        "        characterSet.add(token.lemma_)\n",
        "      elif (token.lemma_ == \"I\") or (token.lemma_ == \"you\"):\n",
        "        characterSet.add(token.lemma_)\n",
        "  #create character dict to store word related to characters\n",
        "  characterDict = dict()\n",
        "  for character in characterSet:\n",
        "    characterDict[character] = []\n",
        "\n",
        "   #search for word related to character\n",
        "  for text in corpus:\n",
        "    tokens = nlp(text)\n",
        "    for token in tokens:\n",
        "      if (token.lemma_ in characterSet):\n",
        "        if (token.head.pos_ == 'VERB') or (token.head.pos_ == 'ADJ') or (token.head.pos_ == 'NOUN'):\n",
        "          characterDict[token.lemma_].append(token.head.lemma_)\n",
        "        if (token.head.pos_ == 'AUX') or (token.head.pos_ == 'NOUN'):\n",
        "          for t in token.head.children:\n",
        "            if (t.pos_ == 'ADJ'):\n",
        "              characterDict[token.lemma_].append(t.lemma_)\n",
        "      elif (token.head.lemma_ in characterSet):\n",
        "        if (token.pos_ == 'VERB') or (token.pos_ == 'ADJ') or (token.head.pos_ == 'NOUN'):\n",
        "          characterDict[token.head.lemma_].append(token.lemma_)\n",
        "  return characterDict\n"
      ],
      "metadata": {
        "id": "OlL2jjmguOXd"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = getCharacterEmbedding(processedPrompts)"
      ],
      "metadata": {
        "id": "UmvNWiuf0s2J"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlAfIwqd05Ze",
        "outputId": "7c335099-3d51-4920-cd2e-59385e454010",
        "collapsed": true
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'say': ['say', 'laugh', 'say', 'come'],\n",
              " 'arctic': ['tundra', 'arctic'],\n",
              " \"'s\": ['old', 'character', 'character', 'man', 'dead'],\n",
              " 'Lovecraft': [],\n",
              " 'Tolkien': [],\n",
              " 'Writers': [],\n",
              " 'Woolly': [],\n",
              " 'Service': ['agent'],\n",
              " 'Joker': ['trouble'],\n",
              " 'Dragons': [],\n",
              " 'Democratic': [],\n",
              " 'Pratchett': [],\n",
              " 'Eleven': [],\n",
              " 'Osama': [],\n",
              " 'video': ['game', 'last', 'log'],\n",
              " 'you': ['commit',\n",
              "  'invite',\n",
              "  'die',\n",
              "  'curse',\n",
              "  'find',\n",
              "  'wake',\n",
              "  'hand',\n",
              "  'tell',\n",
              "  'wake',\n",
              "  'reel',\n",
              "  'give',\n",
              "  'receive',\n",
              "  'don',\n",
              "  'go',\n",
              "  'die',\n",
              "  'find',\n",
              "  'present',\n",
              "  'know',\n",
              "  'move',\n",
              "  'drag',\n",
              "  'run',\n",
              "  'interested',\n",
              "  'summon',\n",
              "  'go',\n",
              "  'impress',\n",
              "  'execute',\n",
              "  'go',\n",
              "  'try',\n",
              "  'last',\n",
              "  'first',\n",
              "  'inherit',\n",
              "  'enter',\n",
              "  'remember',\n",
              "  'fast',\n",
              "  'transfer',\n",
              "  'awaken',\n",
              "  'cover',\n",
              "  'look',\n",
              "  'decide',\n",
              "  'kill',\n",
              "  'cross',\n",
              "  'use',\n",
              "  'use',\n",
              "  'live',\n",
              "  'become',\n",
              "  'have',\n",
              "  'have',\n",
              "  'hear',\n",
              "  'have',\n",
              "  'require',\n",
              "  'leave',\n",
              "  'watch',\n",
              "  'find',\n",
              "  'keep',\n",
              "  'get',\n",
              "  'select',\n",
              "  'recognize',\n",
              "  'commit',\n",
              "  'die',\n",
              "  'deal',\n",
              "  'pull',\n",
              "  'pull',\n",
              "  'know',\n",
              "  'select',\n",
              "  'teleport',\n",
              "  'think',\n",
              "  'tell',\n",
              "  'encourage',\n",
              "  'sure',\n",
              "  'real',\n",
              "  'sure',\n",
              "  'keep',\n",
              "  'wake',\n",
              "  'play',\n",
              "  'fall',\n",
              "  'wake',\n",
              "  'die',\n",
              "  'tell',\n",
              "  'tell',\n",
              "  'have',\n",
              "  'have',\n",
              "  'begin',\n",
              "  'tear',\n",
              "  'make',\n",
              "  'wake',\n",
              "  'clone',\n",
              "  'about',\n",
              "  'commit',\n",
              "  'assign',\n",
              "  'follow',\n",
              "  'bless',\n",
              "  'begin',\n",
              "  'have',\n",
              "  'work',\n",
              "  'find',\n",
              "  'remember',\n",
              "  'get',\n",
              "  'see',\n",
              "  'skydive',\n",
              "  'present',\n",
              "  'step',\n",
              "  'have',\n",
              "  'hear',\n",
              "  'understand',\n",
              "  'move',\n",
              "  'feel',\n",
              "  'have',\n",
              "  'hear',\n",
              "  'have',\n",
              "  'have',\n",
              "  'curse',\n",
              "  'make',\n",
              "  'hear',\n",
              "  'commit',\n",
              "  'dead',\n",
              "  'know'],\n",
              " 'Jesus': ['son'],\n",
              " 'Story': [],\n",
              " 'Old': [],\n",
              " 'Rowling': [],\n",
              " 'Terry': [],\n",
              " 'Wile': [],\n",
              " 'US': [],\n",
              " 'Riding': [],\n",
              " 'canadian': ['killer', 'apologetic', 'canadian', 'serial'],\n",
              " 'Castle': [],\n",
              " '50': ['%'],\n",
              " 'progress': ['the', 'judge'],\n",
              " 'Red': [],\n",
              " 'Congo': [],\n",
              " 'Potter': [],\n",
              " '1.1': ['progress'],\n",
              " 'Jupiter': [],\n",
              " 'tindere': ['tindere', 'try'],\n",
              " 'Recents': ['folder'],\n",
              " 'EU': ['write', 'die', 'write', 'pass', 'write', 'face'],\n",
              " 'Shel': [],\n",
              " 'Coyote': ['decide'],\n",
              " 'Glenn': ['write'],\n",
              " 'Trillion': [],\n",
              " 'Superman': ['face'],\n",
              " 'Zealand': [],\n",
              " '3': ['year', 'kid', 'return'],\n",
              " 'Bin': [],\n",
              " 'Fi': [],\n",
              " 'North': [],\n",
              " 'Bloc': [],\n",
              " 'Hood': ['white'],\n",
              " 'Gotham': ['protect'],\n",
              " 'Time': ['capsule'],\n",
              " 'I': ['chase', 'kill', 'say', 'tell', 'walk', 'cold', \"'\", 'm', 'tell'],\n",
              " 'Woody': ['sneak'],\n",
              " 'Kim': [],\n",
              " 'Travel': ['invent'],\n",
              " 'King': [],\n",
              " 'Secret': [],\n",
              " 'Un': [],\n",
              " 'Harry': [],\n",
              " 'Logs': ['name'],\n",
              " 'New': [],\n",
              " 'Satan': [],\n",
              " 'Greek': [],\n",
              " 'Earth': ['setting'],\n",
              " 'Laden': ['kill'],\n",
              " 'Sci': ['fi'],\n",
              " 'White': [],\n",
              " 'Epic': [],\n",
              " '%': ['water', 'risk', 'progress'],\n",
              " 'Universe': [],\n",
              " 'Mammoth': ['clone'],\n",
              " 'Ones': ['suffer'],\n",
              " 'of': ['full',\n",
              "  'year',\n",
              "  'track',\n",
              "  'decade',\n",
              "  'feat',\n",
              "  'inexplainable',\n",
              "  'size',\n",
              "  'body',\n",
              "  'abyss',\n",
              "  'picture',\n",
              "  'multiple',\n",
              "  'ending',\n",
              "  'leave',\n",
              "  'end',\n",
              "  'machine',\n",
              "  'realm',\n",
              "  'lunatic',\n",
              "  'front',\n",
              "  'board',\n",
              "  'scene',\n",
              "  'awkward',\n",
              "  'middle',\n",
              "  'thousand',\n",
              "  'angle',\n",
              "  'issue',\n",
              "  'amount',\n",
              "  'different',\n",
              "  'end',\n",
              "  'style',\n",
              "  'stream',\n",
              "  'flashback',\n",
              "  'thousand',\n",
              "  'year',\n",
              "  'cycle',\n",
              "  'meet',\n",
              "  'end',\n",
              "  'team',\n",
              "  'spirit',\n",
              "  'format',\n",
              "  'personification',\n",
              "  'crime',\n",
              "  'writer',\n",
              "  'middle',\n",
              "  'leader',\n",
              "  'think',\n",
              "  'secretary',\n",
              "  'part',\n",
              "  'deep',\n",
              "  'pocket',\n",
              "  'isolated',\n",
              "  'cluster',\n",
              "  'full',\n",
              "  'superpower',\n",
              "  'middle',\n",
              "  'group',\n",
              "  'slander',\n",
              "  'block',\n",
              "  'first',\n",
              "  'dream',\n",
              "  'group',\n",
              "  'copy',\n",
              "  'army',\n",
              "  'post',\n",
              "  '-',\n",
              "  'modern',\n",
              "  'leader',\n",
              "  'group',\n",
              "  'flee',\n",
              "  'risk',\n",
              "  'calculated',\n",
              "  'progress',\n",
              "  'batch',\n",
              "  'next',\n",
              "  'log',\n",
              "  'tired',\n",
              "  'hear',\n",
              "  'point',\n",
              "  'view',\n",
              "  'point',\n",
              "  'view',\n",
              "  'burrow',\n",
              "  'massive',\n",
              "  'box',\n",
              "  'ice',\n",
              "  'moon',\n",
              "  'icy',\n",
              "  'list',\n",
              "  'number',\n",
              "  'corner',\n",
              "  'thought',\n",
              "  'outcome',\n",
              "  'possible',\n",
              "  'negative'],\n",
              " 'Creator': [],\n",
              " 'JK': [],\n",
              " 'Squad': [],\n",
              " 'Dungeons': ['play'],\n",
              " 'Muggle': ['technology'],\n",
              " 'Spices': [],\n",
              " '1': ['rewind', 'life', 'year', '%'],\n",
              " 'un': ['resign'],\n",
              " 'Machen': [],\n",
              " '60': ['%'],\n",
              " 'Demon': ['good'],\n",
              " 'log': ['contain'],\n",
              " 'Korea': [],\n",
              " 'Herbs': [],\n",
              " 'fi': ['-', 'fantasy', 'high'],\n",
              " 'Toy': [],\n",
              " 'Europa': [],\n",
              " 'Arthur': ['court'],\n",
              " 'Merlin': ['hand'],\n",
              " 'JRR': [],\n",
              " 'Batman': ['die'],\n",
              " 'Fantasy': [],\n",
              " 'Vatican': ['declare'],\n",
              " 'Middle': [],\n",
              " 'E': [],\n",
              " 'Republic': [],\n",
              " 'Andy': ['elderly'],\n",
              " 'Jong': [],\n",
              " 'Silverstein': ['write'],\n",
              " 'Dollar': [],\n",
              " 'Great': []}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = tokenizer(\"I am groot\")"
      ],
      "metadata": {
        "id": "Q8xUyp8M6I78"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent[0].lemma_ == \"I\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjBnwr1GWkR5",
        "outputId": "0015fbcf-5655-4c4f-bf0c-fd1278b8ac7f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Event2Event"
      ],
      "metadata": {
        "id": "FpABLwkch--1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creation of the vocabulary"
      ],
      "metadata": {
        "id": "qdK3bGYgIOX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to create our vocabulary (inspired by pytorch RNN creation and lecture)"
      ],
      "metadata": {
        "id": "slqH4sresJ2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"NoObject\": 0}\n",
        "        self.word2count = {\"NoObject\": 1}\n",
        "        self.index2word = {0: \"NoObject\"}\n",
        "        self.n_words = 1\n",
        "        self.count = 1\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in tokenizer(sentence):\n",
        "            self.addWord(word.lemma_)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "            self.count += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "            self.count += 1"
      ],
      "metadata": {
        "id": "VgQ8oJKPsHLm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Vocab('vocabulary')"
      ],
      "metadata": {
        "id": "hVWROvNAsm6D"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for story in processedStories:\n",
        "    vocab.addSentence(story)\n",
        "for prompt in processedPrompts:\n",
        "    vocab.addSentence(prompt)"
      ],
      "metadata": {
        "id": "UCLnyKtPsvca"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab.name + \" size : \" + str(vocab.n_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh2AVBuQtB1E",
        "outputId": "972f7705-df27-4fae-d1b0-ff7a25e717e1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary size : 7884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creation of the pairs as input and target"
      ],
      "metadata": {
        "id": "uLAncAnzIZcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then our pair of 2 sucessives events :"
      ],
      "metadata": {
        "id": "2hOAf3CX9qcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainPairsEvent = []\n",
        "for j in range(len(trainPromptsEvents)):\n",
        "    concat = trainPromptsEvents[j] + trainStoriesEvents[j]\n",
        "    for i in range(len(concat) - 1):\n",
        "        trainPairsEvent.append([concat[i],concat[i+1]])"
      ],
      "metadata": {
        "id": "kRX5ZJBi9us-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainPairsEvent[20][0].toString() + \" -> \" + trainPairsEvent[20][1].toString())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gKj-KV9BPDP",
        "outputId": "39de2161-e510-450a-95bc-e47448af7617"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I, be, none, NoObject -> we, learn, more, NoObject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainPairsEvent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vhghfGwzJgi",
        "outputId": "4b207f35-b1c8-4e16-86c0-7d9079e22938"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5666"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testPairsEvent = []\n",
        "for j in range(len(testPromptsEvents)):\n",
        "    concat = testPromptsEvents[j] + testStoriesEvents[j]\n",
        "    for i in range(len(concat) - 1):\n",
        "        testPairsEvent.append([concat[i],concat[i+1]])"
      ],
      "metadata": {
        "id": "Ifm2fzzZtzpM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eventVocab = Vocab('eventVocab')\n",
        "for pair in trainPairsEvent:\n",
        "    for token in pair[0].toList():\n",
        "        if not(token == \"NoObject\"):\n",
        "            eventVocab.addWord(token)\n",
        "    for token in pair[1].toList():\n",
        "        if not(token == \"NoObject\"):\n",
        "            eventVocab.addWord(token)\n",
        "for pair in testPairsEvent:\n",
        "    for token in pair[0].toList():\n",
        "        if not(token == \"NoObject\"):\n",
        "            eventVocab.addWord(token)\n",
        "    for token in pair[1].toList():\n",
        "        if not(token == \"NoObject\"):\n",
        "            eventVocab.addWord(token)"
      ],
      "metadata": {
        "id": "LokBnRCEOkTL"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eventVocab.word2index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CHGBtHjAEjH",
        "outputId": "5b3ca4e2-12fe-4bf3-add6-6ba1cf699d3a",
        "collapsed": true
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NoObject': 0,\n",
              " 'sunflower': 1,\n",
              " 'be': 2,\n",
              " 'sinflower': 3,\n",
              " 'you': 4,\n",
              " 'commit': 5,\n",
              " 'one': 6,\n",
              " 'they': 7,\n",
              " 'invite': 8,\n",
              " 'I': 9,\n",
              " 'have': 10,\n",
              " 'monster': 11,\n",
              " 'who': 12,\n",
              " 'destroy': 13,\n",
              " 'neighborhood': 14,\n",
              " 'she': 15,\n",
              " 'swirl': 16,\n",
              " 'glass': 17,\n",
              " 'smell': 18,\n",
              " 'tang': 19,\n",
              " 'spike': 20,\n",
              " 'it': 21,\n",
              " 'pervert': 22,\n",
              " 'know': 23,\n",
              " 'kind': 24,\n",
              " 'people': 25,\n",
              " 'get': 26,\n",
              " 'yard': 27,\n",
              " 'think': 28,\n",
              " 'what': 29,\n",
              " 'keep': 30,\n",
              " 'mouth': 31,\n",
              " 'both': 32,\n",
              " 'set': 33,\n",
              " 'Carolyn': 34,\n",
              " 'need': 35,\n",
              " 'none': 36,\n",
              " 'we': 37,\n",
              " 'learn': 38,\n",
              " 'more': 39,\n",
              " 'that': 40,\n",
              " 'end': 41,\n",
              " 'conversation': 42,\n",
              " 'trade': 43,\n",
              " 'look': 44,\n",
              " 'Susan': 45,\n",
              " 'do': 46,\n",
              " 'this': 47,\n",
              " 'say': 48,\n",
              " 'goodbyes': 49,\n",
              " 'complete': 50,\n",
              " 'spend': 51,\n",
              " 'time': 52,\n",
              " 'roll': 53,\n",
              " 'eye': 54,\n",
              " 'take': 55,\n",
              " 'all': 56,\n",
              " 'neighbor': 57,\n",
              " 'leave': 58,\n",
              " 'porch': 59,\n",
              " 'bash': 60,\n",
              " 'elm': 61,\n",
              " 'change': 62,\n",
              " 'color': 63,\n",
              " 'house': 64,\n",
              " 'whirring': 65,\n",
              " 'line': 66,\n",
              " 'street': 67,\n",
              " 'sound': 68,\n",
              " 'make': 69,\n",
              " 'door': 70,\n",
              " 'man': 71,\n",
              " 'contact': 72,\n",
              " 'see': 73,\n",
              " 'rest': 74,\n",
              " 'he': 75,\n",
              " 'approach': 76,\n",
              " 'handshake': 77,\n",
              " 'tower': 78,\n",
              " 'tall': 79,\n",
              " 'brown': 80,\n",
              " 'wear': 81,\n",
              " 'suit': 82,\n",
              " 'introduce': 83,\n",
              " 'myself': 84,\n",
              " 'm': 85,\n",
              " 'attorney': 86,\n",
              " 'downtown': 87,\n",
              " 'burn': 88,\n",
              " 'hole': 89,\n",
              " 'add': 90,\n",
              " 'murderer': 91,\n",
              " 'seven': 92,\n",
              " 'weren': 93,\n",
              " 't': 94,\n",
              " 'ring': 95,\n",
              " 'doorbell': 96,\n",
              " 'smooth': 97,\n",
              " 'dress': 98,\n",
              " 'Alan': 99,\n",
              " 'answer': 100,\n",
              " 'exchange': 101,\n",
              " 'greeting': 102,\n",
              " 'usher': 103,\n",
              " 'feature': 104,\n",
              " 'vase': 105,\n",
              " '*': 106,\n",
              " 'those': 107,\n",
              " 'mean': 108,\n",
              " 'kiss': 109,\n",
              " 'two': 110,\n",
              " 'find': 111,\n",
              " 'friend': 112,\n",
              " 'curse': 113,\n",
              " 'wander': 114,\n",
              " 'plane': 115,\n",
              " 'thing': 116,\n",
              " 'anything': 117,\n",
              " 'People': 118,\n",
              " 'cross': 119,\n",
              " 'path': 120,\n",
              " 'feel': 121,\n",
              " 'sense': 122,\n",
              " 'burst': 123,\n",
              " 'help': 124,\n",
              " 'much': 125,\n",
              " 'Corpse': 126,\n",
              " 'right': 127,\n",
              " 'place': 128,\n",
              " 'which': 129,\n",
              " 'pull': 130,\n",
              " 'assure': 131,\n",
              " 'tug': 132,\n",
              " 'word': 133,\n",
              " 'bring': 134,\n",
              " 'voice': 135,\n",
              " 'matter': 136,\n",
              " 'meet': 137,\n",
              " 'his': 138,\n",
              " 'resist': 139,\n",
              " 'urge': 140,\n",
              " 'raise': 141,\n",
              " 'week': 142,\n",
              " 'stop': 143,\n",
              " 'instant': 144,\n",
              " 'soul': 145,\n",
              " 'Jack': 146,\n",
              " 'human': 147,\n",
              " 'fear': 148,\n",
              " 'mate': 149,\n",
              " 'ignore': 150,\n",
              " 'pattering': 151,\n",
              " 'squeeze': 152,\n",
              " 'fist': 153,\n",
              " 'skeleton': 154,\n",
              " 'magic': 155,\n",
              " 'hound': 156,\n",
              " 'back': 157,\n",
              " 'Satan': 158,\n",
              " 'bite': 159,\n",
              " 'grind': 160,\n",
              " 'chuckle': 161,\n",
              " 'let': 162,\n",
              " 'deep': 163,\n",
              " 'like': 164,\n",
              " 'revulsion': 165,\n",
              " 'want': 166,\n",
              " 'trouble': 167,\n",
              " 'Craig': 168,\n",
              " 'something': 169,\n",
              " 'irk': 170,\n",
              " 'condemn': 171,\n",
              " 'brain': 172,\n",
              " 'Coyote': 173,\n",
              " 'call': 174,\n",
              " 'consultant': 175,\n",
              " 'wave': 176,\n",
              " 'skew': 177,\n",
              " 'view': 178,\n",
              " 'lamp': 179,\n",
              " 'provide': 180,\n",
              " 'light': 181,\n",
              " 'kill': 182,\n",
              " 'Wile': 183,\n",
              " 'tell': 184,\n",
              " 'bird': 185,\n",
              " 'give': 186,\n",
              " 'pwice': 187,\n",
              " 'slam': 188,\n",
              " '5000': 189,\n",
              " 'bare': 190,\n",
              " 'tooth': 191,\n",
              " 'Fudd': 192,\n",
              " 'professional': 193,\n",
              " 'stare': 194,\n",
              " 'barrel': 195,\n",
              " 'maker': 196,\n",
              " 'carry': 197,\n",
              " 'skull': 198,\n",
              " 'question': 199,\n",
              " 'hunt': 200,\n",
              " 'creature': 201,\n",
              " 'contract': 202,\n",
              " 'booze': 203,\n",
              " 'strike': 204,\n",
              " 'Merlin': 205,\n",
              " 'wish': 206,\n",
              " 'object': 207,\n",
              " 'hand': 208,\n",
              " 'box': 209,\n",
              " 'day': 210,\n",
              " 'lord': 211,\n",
              " 'Smallpox': 212,\n",
              " 'everyone': 213,\n",
              " 'trap': 214,\n",
              " 'army': 215,\n",
              " 'drone': 216,\n",
              " 'knock': 217,\n",
              " 'item': 218,\n",
              " 'plan': 219,\n",
              " 'incase': 220,\n",
              " 'buy': 221,\n",
              " 'evacuate': 222,\n",
              " 'many': 223,\n",
              " 'defender': 224,\n",
              " 'patience': 225,\n",
              " 'sure': 226,\n",
              " 'hell': 227,\n",
              " 'dude': 228,\n",
              " 'king': 229,\n",
              " 'three': 230,\n",
              " 'mask': 231,\n",
              " 'achieve': 232,\n",
              " 'objective': 233,\n",
              " 'shot': 234,\n",
              " 'wizard': 235,\n",
              " 'armor': 236,\n",
              " 'piece': 237,\n",
              " 'vampire': 238,\n",
              " 'wake': 239,\n",
              " 'fill': 240,\n",
              " 'way': 241,\n",
              " 'sapling': 242,\n",
              " 'pass': 243,\n",
              " 'wife': 244,\n",
              " 'contain': 245,\n",
              " 'picture': 246,\n",
              " 'rule': 247,\n",
              " 'locket': 248,\n",
              " 'heart': 249,\n",
              " 'second': 250,\n",
              " 'after': 251,\n",
              " 'person': 252,\n",
              " 'good': 253,\n",
              " 'fish': 254,\n",
              " 'partner': 255,\n",
              " 'sin': 256,\n",
              " 'clutch': 257,\n",
              " 'forgo': 258,\n",
              " 'glory': 259,\n",
              " 'read': 260,\n",
              " 'waste': 261,\n",
              " 'minute': 262,\n",
              " 'AM': 263,\n",
              " 'fuck': 264,\n",
              " 'cover': 265,\n",
              " 'head': 266,\n",
              " 'slide': 267,\n",
              " 'red': 268,\n",
              " 'use': 269,\n",
              " 'mattress': 270,\n",
              " 'drag': 271,\n",
              " 'accomplish': 272,\n",
              " 'part': 273,\n",
              " 'prepare': 274,\n",
              " 'increase': 275,\n",
              " 'level': 276,\n",
              " 'adjust': 277,\n",
              " 'water': 278,\n",
              " 'warmth': 279,\n",
              " 'envelop': 280,\n",
              " 'body': 281,\n",
              " 'wash': 282,\n",
              " 'thought': 283,\n",
              " 'hear': 284,\n",
              " 'noise': 285,\n",
              " 'reach': 286,\n",
              " 'climax': 287,\n",
              " 'curiosity': 288,\n",
              " 'neither': 289,\n",
              " 'Albert': 290,\n",
              " 'block': 291,\n",
              " 'radiation': 292,\n",
              " 'cast': 293,\n",
              " 'shadow': 294,\n",
              " 'cloud': 295,\n",
              " 'encroach': 296,\n",
              " 'sky': 297,\n",
              " 'draw': 298,\n",
              " 'breath': 299,\n",
              " 'notice': 300,\n",
              " 'extinction': 301,\n",
              " 'shade': 302,\n",
              " 'attack': 303,\n",
              " 'hit': 304,\n",
              " 'wound': 305,\n",
              " 'lessen': 306,\n",
              " 'worry': 307,\n",
              " 'artery': 308,\n",
              " 'grab': 309,\n",
              " 'key': 310,\n",
              " 'last': 311,\n",
              " 'survival': 312,\n",
              " 'fiancé': 313,\n",
              " 'bad': 314,\n",
              " 'shed': 315,\n",
              " 'tear': 316,\n",
              " 'home': 317,\n",
              " 'press': 318,\n",
              " 'foot': 319,\n",
              " 'direction': 320,\n",
              " 'ship': 321,\n",
              " 'survive': 322,\n",
              " 'onslaught': 323,\n",
              " 'refuge': 324,\n",
              " 'humanity': 325,\n",
              " 'clear': 326,\n",
              " 'throat': 327,\n",
              " 'name': 328,\n",
              " 'Peter': 329,\n",
              " 'guess': 330,\n",
              " 'beginning': 331,\n",
              " 'wardrobe': 332,\n",
              " 'sister': 333,\n",
              " 'portal': 334,\n",
              " 'open': 335,\n",
              " 'join': 336,\n",
              " 'bunch': 337,\n",
              " 'sell': 338,\n",
              " 'figure': 339,\n",
              " 'install': 340,\n",
              " 'four': 341,\n",
              " 'forty': 342,\n",
              " 'live': 343,\n",
              " 'life': 344,\n",
              " 'sort': 345,\n",
              " 'overthrow': 346,\n",
              " 'government': 347,\n",
              " 'fight': 348,\n",
              " 'resistance': 349,\n",
              " 'run': 350,\n",
              " 'sword': 351,\n",
              " 'gurgling': 352,\n",
              " 'close': 353,\n",
              " 'anybody': 354,\n",
              " 'update': 355,\n",
              " 'hate': 356,\n",
              " 'tollbooth': 357,\n",
              " 'send': 358,\n",
              " 'task': 359,\n",
              " 'ask': 360,\n",
              " 'improvement': 361,\n",
              " 'handle': 362,\n",
              " 'gate': 363,\n",
              " 'accept': 364,\n",
              " 'Buffy': 365,\n",
              " 'apocalypse': 366,\n",
              " 'summarize': 367,\n",
              " 'year': 368,\n",
              " 'story': 369,\n",
              " 'Dorothy': 370,\n",
              " 'receive': 371,\n",
              " 'card': 372,\n",
              " 'depict': 373,\n",
              " 'pile': 374,\n",
              " 'One': 375,\n",
              " 'project': 376,\n",
              " 'Section': 377,\n",
              " 'department': 378,\n",
              " 'display': 379,\n",
              " 'brochure': 380,\n",
              " 'pick': 381,\n",
              " 'pamphlet': 382,\n",
              " 'spin': 383,\n",
              " 'physics': 384,\n",
              " 'shelf': 385,\n",
              " 'offer': 386,\n",
              " 'Invasion': 387,\n",
              " 'country': 388,\n",
              " 'convert': 389,\n",
              " 'seawater': 390,\n",
              " 'catch': 391,\n",
              " 'present': 392,\n",
              " 'decision': 393,\n",
              " 'don': 394,\n",
              " 'quadrillion': 395,\n",
              " 'air': 396,\n",
              " 'Bishop': 397,\n",
              " 'begin': 398,\n",
              " 'campaign': 399,\n",
              " 'heretic': 400,\n",
              " 'few': 401,\n",
              " 'ruin': 402,\n",
              " 'job': 403,\n",
              " 'civilian': 404,\n",
              " 'nuke': 405,\n",
              " 'sputter': 406,\n",
              " 'marine': 407,\n",
              " 'roar': 408,\n",
              " 'offense': 409,\n",
              " 'sentence': 410,\n",
              " 'cluster': 411,\n",
              " 'cleanse': 412,\n",
              " 'throw': 413,\n",
              " 'hat': 414,\n",
              " 'purge': 415,\n",
              " 'universe': 416,\n",
              " 'resemble': 417,\n",
              " 'pour': 418,\n",
              " 'hail': 419,\n",
              " 'captain': 420,\n",
              " 'chew': 421,\n",
              " 'cigar': 422,\n",
              " 'got': 423,\n",
              " 'reinforcement': 424,\n",
              " 'order': 425,\n",
              " 'smoke': 426,\n",
              " 'movement': 427,\n",
              " 'stub': 428,\n",
              " 'protect': 429,\n",
              " 'Gotham': 430,\n",
              " 'stand': 431,\n",
              " 'spy': 432,\n",
              " 'scene': 433,\n",
              " 'city': 434,\n",
              " 'move': 435,\n",
              " 'gaze': 436,\n",
              " 'surge': 437,\n",
              " 'laugh': 438,\n",
              " 'shiver': 439,\n",
              " 'Cobblepot': 440,\n",
              " 'sir': 441,\n",
              " 'clown': 442,\n",
              " 'mantle': 443,\n",
              " 'whip': 444,\n",
              " 'goon': 445,\n",
              " 'heel': 446,\n",
              " 'crack': 447,\n",
              " 'avenger': 448,\n",
              " 'contemplate': 449,\n",
              " 'future': 450,\n",
              " 'miss': 451,\n",
              " 'Clown': 452,\n",
              " 'hero': 453,\n",
              " 'quote': 454,\n",
              " 'watch': 455,\n",
              " 'show': 456,\n",
              " 'religion': 457,\n",
              " 'deity': 458,\n",
              " 'scratch': 459,\n",
              " 'lot': 460,\n",
              " 'fascinate': 461,\n",
              " 'text': 462,\n",
              " 'earn': 463,\n",
              " 'doctorate': 464,\n",
              " 'in': 465,\n",
              " 'less': 466,\n",
              " 'contradict': 467,\n",
              " 'other': 468,\n",
              " 'Allah': 469,\n",
              " 'bid': 470,\n",
              " 'influence': 471,\n",
              " 'someone': 472,\n",
              " 'return': 473,\n",
              " 'everything': 474,\n",
              " 'serve': 475,\n",
              " 'study': 476,\n",
              " 'torture': 477,\n",
              " 'promote': 478,\n",
              " 'debate': 479,\n",
              " 'auctioneer': 480,\n",
              " 'afford': 481,\n",
              " 'price': 482,\n",
              " 'top': 483,\n",
              " 'put': 484,\n",
              " 'pay': 485,\n",
              " 'Grant': 486,\n",
              " 'check': 487,\n",
              " 'system': 488,\n",
              " 'Paul': 489,\n",
              " 'puppy': 490,\n",
              " 'himself': 491,\n",
              " 'drawl': 492,\n",
              " 'syllable': 493,\n",
              " 'dinosaur': 494,\n",
              " 'shield': 495,\n",
              " 'little': 496,\n",
              " 'verify': 497,\n",
              " 'activate': 498,\n",
              " 'circuit': 499,\n",
              " 'avoid': 500,\n",
              " 'confusion': 501,\n",
              " 'exhale': 502,\n",
              " 'shout': 503,\n",
              " 'extend': 504,\n",
              " 'contort': 505,\n",
              " 'swell': 506,\n",
              " 'moving': 507,\n",
              " 'become': 508,\n",
              " 'painful': 509,\n",
              " 'realize': 510,\n",
              " 'motion': 511,\n",
              " 'forget': 512,\n",
              " 'nothing': 513,\n",
              " 'Companion': 514,\n",
              " 'Doctor': 515,\n",
              " 'Tardis': 516,\n",
              " 'button': 517,\n",
              " 'doctor': 518,\n",
              " 'companion': 519,\n",
              " 'Clara': 520,\n",
              " 'Rory': 521,\n",
              " 're': 522,\n",
              " 'Time': 523,\n",
              " 'point': 524,\n",
              " 'Energy': 525,\n",
              " 'build': 526,\n",
              " 'ready': 527,\n",
              " 'sci': 528,\n",
              " '-': 529,\n",
              " 'fi': 530,\n",
              " 'isn': 531,\n",
              " 'fiction': 532,\n",
              " 'reality': 533,\n",
              " 'face': 534,\n",
              " 'irony': 535,\n",
              " 'joke': 536,\n",
              " 'glance': 537,\n",
              " 'nervous': 538,\n",
              " 'stalk': 539,\n",
              " 'hall': 540,\n",
              " 'car': 541,\n",
              " 'sight-': 542,\n",
              " 'town': 543,\n",
              " 'vary': 544,\n",
              " 'dust': 545,\n",
              " 'station': 546,\n",
              " 'lead': 547,\n",
              " 'clue': 548,\n",
              " 'stair': 549,\n",
              " 'Ron': 550,\n",
              " 'slough': 551,\n",
              " 'remember': 552,\n",
              " 'Greeks': 553,\n",
              " 'Jupiter': 554,\n",
              " 'god': 555,\n",
              " 'Romans': 556,\n",
              " 'planet': 557,\n",
              " 'Zeus': 558,\n",
              " 'aqueduct': 559,\n",
              " 'Europe': 560,\n",
              " 'bridge': 561,\n",
              " 'Huns': 562,\n",
              " 'beat': 563,\n",
              " 'electricity': 564,\n",
              " 'castle': 565,\n",
              " 'steal': 566,\n",
              " 'money': 567,\n",
              " 'Hood': 568,\n",
              " 'shoot': 569,\n",
              " 'arrow': 570,\n",
              " 'split': 571,\n",
              " 'nobody': 572,\n",
              " 'Ages': 573,\n",
              " 'vision': 574,\n",
              " 'Zeenak': 575,\n",
              " 'rub': 576,\n",
              " 'dialect': 577,\n",
              " 'English': 578,\n",
              " 'parse': 579,\n",
              " 'essay': 580,\n",
              " 'chase': 581,\n",
              " 'dragon': 582,\n",
              " 'Jared': 583,\n",
              " 'try': 584,\n",
              " 'ride': 585,\n",
              " 'bike': 586,\n",
              " 'cone': 587,\n",
              " 'collect': 588,\n",
              " 'explore': 589,\n",
              " 'wood': 590,\n",
              " 'type': 591,\n",
              " 'boy': 592,\n",
              " 'plenty': 593,\n",
              " 'memory': 594,\n",
              " 'hold': 595,\n",
              " 'dearest': 596,\n",
              " 'shape': 597,\n",
              " 'animal': 598,\n",
              " 'leg': 599,\n",
              " 'describe': 600,\n",
              " 'world': 601,\n",
              " 'million': 602,\n",
              " 'appointment': 603,\n",
              " 'drop': 604,\n",
              " 'deal': 605,\n",
              " 'lose': 606,\n",
              " 'courage': 607,\n",
              " 'yours': 608,\n",
              " 'school': 609,\n",
              " 'turn': 610,\n",
              " 'thirteen': 611,\n",
              " 'mourner': 612,\n",
              " 'everybody': 613,\n",
              " 'choose': 614,\n",
              " 'challenge': 615,\n",
              " 'chance': 616,\n",
              " 'nest': 617,\n",
              " 'guy': 618,\n",
              " 'date': 619,\n",
              " 'swipe': 620,\n",
              " 'Jake': 621,\n",
              " 'secure': 622,\n",
              " 's': 623,\n",
              " 'addy': 624,\n",
              " 'excited': 625,\n",
              " 'super': 626,\n",
              " 'sarahbae91': 627,\n",
              " 'Sarah': 628,\n",
              " 'Bacon': 629,\n",
              " 'drink': 630,\n",
              " '6': 631,\n",
              " 'come': 632,\n",
              " 'Jakey': 633,\n",
              " 'machine': 634,\n",
              " 'upgrade': 635,\n",
              " 'globe': 636,\n",
              " 'office': 637,\n",
              " 'sphere': 638,\n",
              " 'earther': 639,\n",
              " 'flat': 640,\n",
              " 'fucking': 641,\n",
              " 'create': 642,\n",
              " 'paradox': 643,\n",
              " 'zoom': 644,\n",
              " 'impatient': 645,\n",
              " 'sock': 646,\n",
              " 'single': 647,\n",
              " 'individual': 648,\n",
              " 'reminder': 649,\n",
              " 'bullshit': 650,\n",
              " 'will': 651,\n",
              " 'most': 652,\n",
              " 'require': 653,\n",
              " 'visit': 654,\n",
              " 'couple': 655,\n",
              " 'share': 656,\n",
              " 'explain': 657,\n",
              " 'spread': 658,\n",
              " 'arm': 659,\n",
              " 'unhappy': 660,\n",
              " 'understand': 661,\n",
              " 'locate': 662,\n",
              " 'headband': 663,\n",
              " 'computer': 664,\n",
              " 'augment': 665,\n",
              " 'process': 666,\n",
              " 'develop': 667,\n",
              " 'source': 668,\n",
              " 'track': 669,\n",
              " 'research': 670,\n",
              " 'mystery': 671,\n",
              " 'to': 672,\n",
              " 'framework': 673,\n",
              " 'unlock': 674,\n",
              " 'function': 675,\n",
              " 'eat': 676,\n",
              " 'cake': 677,\n",
              " 'tweak': 678,\n",
              " 'heck': 679,\n",
              " 'implement': 680,\n",
              " 'these': 681,\n",
              " 'fall': 682,\n",
              " 'wistful': 683,\n",
              " 'omnipotence': 684,\n",
              " 'Earth': 685,\n",
              " 'fresh': 686,\n",
              " 'behead': 687,\n",
              " 'encounter': 688,\n",
              " 'action': 689,\n",
              " 'Bar': 690,\n",
              " 'position': 691,\n",
              " 'squad': 692,\n",
              " 'halt': 693,\n",
              " 'direct': 694,\n",
              " 'footstep': 695,\n",
              " 'whine': 696,\n",
              " 'switch': 697,\n",
              " 'strength': 698,\n",
              " 'surround': 699,\n",
              " 'group': 700,\n",
              " 'rider': 701,\n",
              " 'spear': 702,\n",
              " 'sheepfucking': 703,\n",
              " 'nzsas': 704,\n",
              " 'prisoner': 705,\n",
              " 'statement': 706,\n",
              " 'HQ': 707,\n",
              " 'ammunition': 708,\n",
              " 'frequency': 709,\n",
              " 'operator': 710,\n",
              " 'horseman': 711,\n",
              " 'lop': 712,\n",
              " 'swing': 713,\n",
              " 'fourth': 714,\n",
              " 'flank': 715,\n",
              " 'bit': 716,\n",
              " 'smile': 717,\n",
              " 'follow': 718,\n",
              " 'cut': 719,\n",
              " 'grass': 720,\n",
              " 'allow': 721,\n",
              " 'concealment': 722,\n",
              " 'neighing': 723,\n",
              " 'care': 724,\n",
              " 'thirty': 725,\n",
              " 'remind': 726,\n",
              " 'baritone': 727,\n",
              " 'sheep': 728,\n",
              " 'treat': 729,\n",
              " 'haul': 730,\n",
              " 'blur': 731,\n",
              " 'fighting': 732,\n",
              " 'Kiwis': 733,\n",
              " 'sight': 734,\n",
              " 'flip': 735,\n",
              " 'selector': 736,\n",
              " 'shoulder': 737,\n",
              " 'AK': 738,\n",
              " 'gallop': 739,\n",
              " 'radio': 740,\n",
              " 'realm': 741,\n",
              " 'eyelid': 742,\n",
              " 'struggle': 743,\n",
              " 'match': 744,\n",
              " 'please': 745,\n",
              " 'honour': 746,\n",
              " 'oro': 747,\n",
              " 'nectar': 748,\n",
              " 'rip': 749,\n",
              " 'necklace': 750,\n",
              " 'dishonour': 751,\n",
              " 'shake': 752,\n",
              " 'W': 753,\n",
              " 'summon': 754,\n",
              " 'Ebhlis': 755,\n",
              " 'bidding': 756,\n",
              " 'assign': 757,\n",
              " 'slice': 758,\n",
              " 'salt': 759,\n",
              " 'hurt': 760,\n",
              " 'mind': 761,\n",
              " 'sacrifice': 762,\n",
              " 'forgive': 763,\n",
              " 'Lord': 764,\n",
              " 'highlight': 765,\n",
              " 'woman': 766,\n",
              " 'stream': 767,\n",
              " 'cheek': 768,\n",
              " 'flame': 769,\n",
              " 'singe': 770,\n",
              " 'circle': 771,\n",
              " 'disgust': 772,\n",
              " 'virgin': 773,\n",
              " 'themselves': 774,\n",
              " 'offen-': 775,\n",
              " 'silence': 776,\n",
              " 'cry': 777,\n",
              " 'spare': 778,\n",
              " 'dignity': 779,\n",
              " 'conjure': 780,\n",
              " 'untie': 781,\n",
              " 'request': 782,\n",
              " 'addition': 783,\n",
              " 'enjoy': 784,\n",
              " 'writing': 785,\n",
              " 'evaluate': 786,\n",
              " 'impress': 787,\n",
              " 'peer': 788,\n",
              " 'Walker': 789,\n",
              " 'stack': 790,\n",
              " 'its': 791,\n",
              " 'fold': 792,\n",
              " 'shirt': 793,\n",
              " 'husband': 794,\n",
              " 'belt': 795,\n",
              " 'd': 796,\n",
              " 'Grace': 797,\n",
              " 'pore': 798,\n",
              " 'album': 799,\n",
              " 'accumulate': 800,\n",
              " 'bedroom': 801,\n",
              " 'mess': 802,\n",
              " 'certificate': 803,\n",
              " 'wall': 804,\n",
              " 'grace': 805,\n",
              " 'tic': 806,\n",
              " 'crinkle': 807,\n",
              " 'nose': 808,\n",
              " 'Black': 809,\n",
              " 'shift': 810,\n",
              " 'expression': 811,\n",
              " 'Noah': 812,\n",
              " 'suitcase': 813,\n",
              " 'mention': 814,\n",
              " 'promotion': 815,\n",
              " 'letter': 816,\n",
              " 'snap': 817,\n",
              " 'briefcase': 818,\n",
              " 'shut': 819,\n",
              " 'pack': 820,\n",
              " 'Gabriel': 821,\n",
              " 'Board': 822,\n",
              " 'yank': 823,\n",
              " 'drawer': 824,\n",
              " 'bottom': 825,\n",
              " 'Show': 826,\n",
              " 'nurse': 827,\n",
              " 'basket': 828,\n",
              " 'son': 829,\n",
              " 'congratulate': 830,\n",
              " 'cab': 831,\n",
              " 'escort': 832,\n",
              " 'drive': 833,\n",
              " 'corner': 834,\n",
              " 'goodbye': 835,\n",
              " 'tidy': 836,\n",
              " 'herself': 837,\n",
              " 'stock': 838,\n",
              " 'sun': 839,\n",
              " 'gradient': 840,\n",
              " 'parchment': 841,\n",
              " 'north': 842,\n",
              " 'purpose': 843,\n",
              " 'Lucia': 844,\n",
              " 'still': 845,\n",
              " 'rebellion': 846,\n",
              " 'her': 847,\n",
              " 'owe': 848,\n",
              " 'wasn': 849,\n",
              " 'fault': 850,\n",
              " 'break': 851,\n",
              " 'camp': 852,\n",
              " 'crest': 853,\n",
              " 'hill': 854,\n",
              " 'night': 855,\n",
              " 'stake': 856,\n",
              " 'claim': 857,\n",
              " 'for': 858,\n",
              " 'rump': 859,\n",
              " 'mob': 860,\n",
              " 'assess': 861,\n",
              " 'situation': 862,\n",
              " 'incur': 863,\n",
              " 'blowback': 864,\n",
              " 'perceive': 865,\n",
              " 'ire': 866,\n",
              " 'comin': 867,\n",
              " 'guard': 868,\n",
              " 'yer': 869,\n",
              " 'inflame': 870,\n",
              " 'whom': 871,\n",
              " 'elder': 872,\n",
              " 'ain': 873,\n",
              " 'leader': 874,\n",
              " 'bray': 875,\n",
              " 'support': 876,\n",
              " 'crowd': 877,\n",
              " 'suffering': 878,\n",
              " 'bell': 879,\n",
              " 'jar': 880,\n",
              " 'sea': 881,\n",
              " 'mistake': 882,\n",
              " 'villager': 883,\n",
              " 'member': 884,\n",
              " 'account': 885,\n",
              " 'trust': 886,\n",
              " 'Jerina': 887,\n",
              " 'family': 888,\n",
              " 'overcome': 889,\n",
              " 'defence': 890,\n",
              " 'doubt': 891,\n",
              " 'tendril': 892,\n",
              " 'suspend': 893,\n",
              " 'lift': 894,\n",
              " 'amulet': 895,\n",
              " 'mage': 896,\n",
              " 'business': 897,\n",
              " 'defy': 898,\n",
              " 'Cabal': 899,\n",
              " 'sit': 900,\n",
              " 'dazed': 901,\n",
              " 'lower': 902,\n",
              " 'Herrold': 903,\n",
              " 'touch': 904,\n",
              " 'peace': 905,\n",
              " 'leyline': 906,\n",
              " 'harm': 907,\n",
              " 'seed': 908,\n",
              " 'sprout': 909,\n",
              " 'disperse': 910,\n",
              " 'movie': 911,\n",
              " 'wind': 912,\n",
              " 'rustle': 913,\n",
              " 'cable': 914,\n",
              " 'first': 915,\n",
              " 'traveller': 916,\n",
              " 'bliss': 917,\n",
              " 'scientist': 918,\n",
              " 'true': 919,\n",
              " 'consume': 920,\n",
              " 'flood': 921,\n",
              " 'X': 922,\n",
              " 'recognise': 923,\n",
              " 'belief': 924,\n",
              " 'whatever': 925,\n",
              " 'span': 926,\n",
              " 'cosmos': 927,\n",
              " 'explanation': 928,\n",
              " 'grasp': 929,\n",
              " 'x': 930,\n",
              " 'control': 931,\n",
              " 'command': 932,\n",
              " 'darkness': 933,\n",
              " 'murder': 934,\n",
              " 'mold': 935,\n",
              " 'cellar': 936,\n",
              " 'push': 937,\n",
              " 'wine': 938,\n",
              " 'survey': 939,\n",
              " 'pool': 940,\n",
              " 'pin': 941,\n",
              " 'suspicion': 942,\n",
              " 'crane': 943,\n",
              " 'neck': 944,\n",
              " 'passage': 945,\n",
              " 'exit': 946,\n",
              " 'corpse': 947,\n",
              " 'child': 948,\n",
              " 'knife': 949,\n",
              " 'dog': 950,\n",
              " 'killer': 951,\n",
              " 'inherit': 952,\n",
              " 'treasure': 953,\n",
              " 'Leo': 954,\n",
              " 'fix': 955,\n",
              " 'uncle': 956,\n",
              " 'stuff': 957,\n",
              " 'nephew': 958,\n",
              " 'pocketwatch': 959,\n",
              " 'trinket': 960,\n",
              " 'clock': 961,\n",
              " 'relive': 962,\n",
              " 'past': 963,\n",
              " 'power': 964,\n",
              " 'fool': 965,\n",
              " 'inscription': 966,\n",
              " 'concern': 967,\n",
              " 'fact': 968,\n",
              " 'click': 969,\n",
              " 'escape': 970,\n",
              " 'reason': 971,\n",
              " 'ours': 972,\n",
              " 'slap': 973,\n",
              " 'gun': 974,\n",
              " 'finger': 975,\n",
              " 'enter': 976,\n",
              " 'background': 977,\n",
              " 'wonder': 978,\n",
              " 'WHOAH': 979,\n",
              " 'icon': 980,\n",
              " 'shortcut': 981,\n",
              " 'url': 982,\n",
              " 'Booking.com': 983,\n",
              " 'opportunity': 984,\n",
              " 'hope': 985,\n",
              " 'document': 986,\n",
              " 'mother': 987,\n",
              " 'write': 988,\n",
              " 'kid': 989,\n",
              " 'go': 990,\n",
              " 'God': 991,\n",
              " 'prompt': 992,\n",
              " 'while': 993,\n",
              " 'D': 994,\n",
              " 'intervention': 995,\n",
              " 'worker': 996,\n",
              " 'chop': 997,\n",
              " 'tree': 998,\n",
              " 'long': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-dUKNmq4QXKt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creation of the data batches"
      ],
      "metadata": {
        "id": "MElsg8rmIxeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromEvent(v, event):\n",
        "    oneHotList = []\n",
        "    for word in event.toList():\n",
        "        if word in v.word2index.keys():\n",
        "          oneHotList.append(v.word2index[word])\n",
        "        else:\n",
        "          oneHotList.append(0)\n",
        "    return oneHotList\n",
        "\n",
        "\n",
        "def tensorFromEvent(v, event):\n",
        "    indexes = indexesFromEvent(v, event)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(v, pair):\n",
        "    input_tensor = tensorFromEvent(v, pair[0])\n",
        "    target_tensor = tensorFromEvent(v, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def sentenceFromTensor(v, tensor):\n",
        "    sentence = []\n",
        "    for index in tensor:\n",
        "        sentence.append(v.index2word[int(index)])\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "Sv-jDtFDI5YO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainPairsEvent[0][0].toString())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daZvertcP6Eu",
        "outputId": "10a0ba2f-e6cb-4912-a098-6dc0c13e7705"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sunflower, be, sinflower, NoObject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1, t2 = tensorsFromPair(eventVocab, trainPairsEvent[0])"
      ],
      "metadata": {
        "id": "8shIvvvoLjSc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BpeA5QHX2he",
        "outputId": "d51712c4-ce7a-4cfc-81b8-c0c150febae0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(batch_size, pairs, vocab):\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, 4), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, 4), dtype=np.int32)\n",
        "\n",
        "    for idx, pair in enumerate(pairs):\n",
        "        inp_tensor, tgt_tensor = tensorsFromPair(vocab, pair)\n",
        "\n",
        "        input_ids[idx, :len(inp_tensor)] = inp_tensor.squeeze()\n",
        "        target_ids[idx, :len(tgt_tensor)] = tgt_tensor.squeeze()\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return train_dataloader"
      ],
      "metadata": {
        "id": "h6RQLi9e8a0V"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "HB3ko6mH97_o"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDL = get_dataloader(batch_size, trainPairsEvent[:500], eventVocab)"
      ],
      "metadata": {
        "id": "ZLVuDomZ9oM_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(trainDL))\n",
        "print(train_features[0])\n",
        "print(train_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih2PGun1-mTf",
        "outputId": "63d6fcfc-98c0-4671-b472-f8e0ce1c043d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  4, 166, 125,   0])\n",
            "tensor([  4, 184,   9,   0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creation of the model"
      ],
      "metadata": {
        "id": "t7fZ38VFIhCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we create a simple RNN encoder-decoder in order to predict the next event with the previous event."
      ],
      "metadata": {
        "id": "qQ7aCvn4nblk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(RNNEncoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input_tensor, hidden):\n",
        "        combined = torch.cat((input_tensor, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        return hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)"
      ],
      "metadata": {
        "id": "XXpC-SY0nx2X"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(RNNDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, hidden):\n",
        "        hidden = self.h2h(hidden)\n",
        "        output = self.h2o(hidden)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n"
      ],
      "metadata": {
        "id": "Y74L3gMYw52w"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "Cd-nZ9zXbs63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use log likelihood to train the model. We get the input as the one hot encoding of the word (vector of size vocab) and get a vector of probability over the vocabulary as output (vector of size vocab)"
      ],
      "metadata": {
        "id": "ucGA8PbWGvjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "GcJW00rbxaHa"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we define the train function as in seq2seq classic tutorial"
      ],
      "metadata": {
        "id": "B12MaDQpbu4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in the paper we define functions to keep tracking of the time computation"
      ],
      "metadata": {
        "id": "AUx2whf6cHgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "Se2qEqzqHza-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function to plot the plot of the loss in the training"
      ],
      "metadata": {
        "id": "Pu-4mwE6df76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "O-uPGXU8dfaT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and the function to train the model on our data"
      ],
      "metadata": {
        "id": "-MJpO7krc9pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "      for i in range(len(batch)):\n",
        "        input_tensor  = batch[0][i]\n",
        "        target_tensor = batch[1][i]\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        hidden_tensor = encoder.init_hidden()\n",
        "\n",
        "        for inp in input_tensor:\n",
        "            hidden_tensor = encoder(inp.view(1,1), hidden_tensor)\n",
        "\n",
        "        outputs_tensor = torch.zeros(len(target_tensor),decoder.output_size)\n",
        "\n",
        "        for trt in range(len(target_tensor)):\n",
        "            output_tensor, hidden_tensor = decoder(hidden_tensor)\n",
        "            outputs_tensor[trt] = output_tensor\n",
        "\n",
        "        #print(outputs_tensor)\n",
        "        loss = criterion(\n",
        "            outputs_tensor,\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "9lpW5yEb7Sa8"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=25, plot_every=25):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    encoder_scheduler = torch.optim.lr_scheduler.StepLR(encoder_optimizer, step_size=50, gamma=0.5)\n",
        "    decoder_scheduler = torch.optim.lr_scheduler.StepLR(decoder_optimizer, step_size=50, gamma=0.5)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer,  criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        encoder_scheduler.step()\n",
        "        decoder_scheduler.step()\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "dxsiPmwzA5d9"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training on our data"
      ],
      "metadata": {
        "id": "KOWM04Brdtaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 200\n",
        "encoder1 = RNNEncoder(1, hidden_size).to(device)\n",
        "decoder1 = RNNDecoder(hidden_size, eventVocab.n_words).to(device)\n",
        "\n",
        "train(trainDL,encoder1, decoder1, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "MJDVYVNodbzy",
        "outputId": "905d5c45-8df8-4fe9-b4f8-c924137a17a6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 14s (- 9m 31s) (25 2%) 9.4697\n",
            "0m 26s (- 8m 22s) (50 5%) 7.4010\n",
            "0m 39s (- 8m 12s) (75 7%) 6.6635\n",
            "0m 53s (- 8m 5s) (100 10%) 6.4002\n",
            "1m 7s (- 7m 50s) (125 12%) 6.1202\n",
            "1m 20s (- 7m 38s) (150 15%) 5.9358\n",
            "1m 35s (- 7m 28s) (175 17%) 5.7530\n",
            "1m 53s (- 7m 32s) (200 20%) 5.6916\n",
            "2m 7s (- 7m 19s) (225 22%) 5.6113\n",
            "2m 19s (- 6m 59s) (250 25%) 5.6124\n",
            "2m 38s (- 6m 56s) (275 27%) 5.5122\n",
            "2m 52s (- 6m 41s) (300 30%) 5.3781\n",
            "3m 7s (- 6m 29s) (325 32%) 5.5171\n",
            "3m 19s (- 6m 10s) (350 35%) 5.4392\n",
            "3m 35s (- 5m 58s) (375 37%) 5.4003\n",
            "3m 46s (- 5m 39s) (400 40%) 5.3438\n",
            "4m 0s (- 5m 25s) (425 42%) 5.3671\n",
            "4m 12s (- 5m 8s) (450 45%) 5.3620\n",
            "4m 28s (- 4m 56s) (475 47%) 5.3852\n",
            "4m 39s (- 4m 39s) (500 50%) 5.4421\n",
            "4m 54s (- 4m 26s) (525 52%) 5.3776\n",
            "5m 5s (- 4m 9s) (550 55%) 5.3883\n",
            "5m 20s (- 3m 56s) (575 57%) 5.4582\n",
            "5m 32s (- 3m 41s) (600 60%) 5.4026\n",
            "5m 44s (- 3m 26s) (625 62%) 5.4413\n",
            "5m 57s (- 3m 12s) (650 65%) 5.3575\n",
            "6m 10s (- 2m 58s) (675 67%) 5.3403\n",
            "6m 24s (- 2m 44s) (700 70%) 5.3585\n",
            "6m 36s (- 2m 30s) (725 72%) 5.4132\n",
            "6m 50s (- 2m 16s) (750 75%) 5.3566\n",
            "7m 5s (- 2m 3s) (775 77%) 5.3217\n",
            "7m 23s (- 1m 50s) (800 80%) 5.4166\n",
            "7m 35s (- 1m 36s) (825 82%) 5.3891\n",
            "7m 55s (- 1m 23s) (850 85%) 5.3887\n",
            "8m 6s (- 1m 9s) (875 87%) 5.3714\n",
            "8m 21s (- 0m 55s) (900 90%) 5.2852\n",
            "8m 32s (- 0m 41s) (925 92%) 5.4176\n",
            "8m 45s (- 0m 27s) (950 95%) 5.4131\n",
            "8m 57s (- 0m 13s) (975 97%) 5.3696\n",
            "9m 11s (- 0m 0s) (1000 100%) 5.3341\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluation"
      ],
      "metadata": {
        "id": "VUmCCgly0UQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makePrediction(input_tensor):\n",
        "    encoder_hidden = encoder1.init_hidden()\n",
        "    input_length = input_tensor.size(0)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_hidden = encoder1(input_tensor[ei].view(1,1), encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.zeros(input_length, device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_outputs = torch.zeros(input_length, dtype=torch.long, device=device)\n",
        "\n",
        "    #every target is of size 4 so target_length = 4\n",
        "    for di in range(4):\n",
        "        decoder_output, decoder_hidden = decoder1(decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1) #return the largest element of the tensor\n",
        "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "        decoder_outputs[di] = topi.long()\n",
        "    return decoder_outputs\n",
        "\n",
        "def makePredictionFromPair(pairEvent):\n",
        "    input_tensor, target_tensor = tensorsFromPair(eventVocab, pairEvent)\n",
        "    return makePrediction(input_tensor)\n"
      ],
      "metadata": {
        "id": "gTLT3dVk1sUB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex = 30\n",
        "d = makePredictionFromPair(testPairsEvent[ex])\n",
        "print(d)\n",
        "d = d.tolist()\n",
        "s = sentenceFromTensor(eventVocab, d)"
      ],
      "metadata": {
        "id": "YDOeV4HK1zmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c588e78-7a86-4f0a-cdc2-6b0cde4e95f6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 9,  2, 29,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbG-9LJV9_oK",
        "outputId": "51d942f9-c5ce-43b7-f23f-0c2c0aba665d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 2, 29, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvFr6YxP6UJ-",
        "outputId": "d7ba42e3-3159-40f6-96a8-432fc39db9c8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'be', 'what', 'NoObject']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testPairsEvent[ex][0].toString()"
      ],
      "metadata": {
        "id": "wAfsgemR6UcP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d11f5f3e-e4bc-4477-dd97-3897226e8835"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I, say, what, NoObject'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testPairsEvent[ex][1].toString()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "ahvqBqhI6epo",
        "outputId": "e8432fe7-0779-4646-a438-1937b09e7500"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I, pay, attention, NoObject'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate our model, we use 2 metrics :\n",
        "\n",
        "\n",
        "*   Perplexity over unigrams\n",
        "*   BiLingual Evaluation Understudy(BLEU)\n",
        "\n"
      ],
      "metadata": {
        "id": "WfEBYsc-XkA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wordProba(word, vocab):\n",
        "    if word in vocab.word2count.keys():\n",
        "      output = vocab.word2count[word] / vocab.count\n",
        "    else:\n",
        "      output = 1e-6\n",
        "    return output"
      ],
      "metadata": {
        "id": "shIh26qObbt1"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(sentence, vocab):\n",
        "    temp = 0\n",
        "    for word in sentence:\n",
        "        p = wordProba(word, vocab)\n",
        "        temp += p * math.log2(p)\n",
        "    return math.pow(2, -temp)"
      ],
      "metadata": {
        "id": "fSLyM1636iiH"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity(s, eventVocab)"
      ],
      "metadata": {
        "id": "B7wwNQqL9SID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e884a5-e077-47a3-8646-97a6b9ee2243"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.573126431780259"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity(testPairsEvent[ex][1].toList(), eventVocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wrQJhyEhtsu",
        "outputId": "5e3159b5-a04a-4668-e0a8-f9dbd067b73c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2617538629338059"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set is a list of pair of event\n",
        "\n",
        "def evaluateEventPerplexity(testSet, vocab):\n",
        "    perplexityScore = 0\n",
        "    for pair in testSet:\n",
        "        prediction = sentenceFromTensor(vocab, makePredictionFromPair(pair).tolist())\n",
        "        perplexityScore += perplexity(prediction, vocab)\n",
        "    return perplexityScore / len(testSet)"
      ],
      "metadata": {
        "id": "40WvkVLah3rU"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexityScore = evaluateEventPerplexity(testPairsEvent, eventVocab)"
      ],
      "metadata": {
        "id": "VyNIKtwk84rI"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(perplexityScore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhlYPnZJ92P6",
        "outputId": "9de58bfd-ec5d-4e23-f8b8-82dd910cf5e9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1751136825174888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateBLEU(testSet):\n",
        "    total_bleu_score = 0\n",
        "    for pair in testSet:\n",
        "        prediction = sentenceFromTensor(vocab, makePredictionFromPair(pair).tolist())\n",
        "        bleu_score = tr.bleu_score.sentence_bleu([pair[1].toList()], prediction, smoothing_function=tr.bleu_score.SmoothingFunction().method1)\n",
        "        total_bleu_score += bleu_score\n",
        "\n",
        "    return total_bleu_score / len(testSet)\n"
      ],
      "metadata": {
        "id": "2jqWpoXNGi-u"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_bleu_score = evaluateBLEU(testPairsEvent)\n",
        "print(f\"Average BLEU Score: {average_bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR9ADQMv-BNb",
        "outputId": "5298ad10-15f2-4e6b-8b44-19e00c2011bd"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 0.03297039253936232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Event2Sentence"
      ],
      "metadata": {
        "id": "400PGfwc-iJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we can generate next event, we need to be able to generate sentences from event. To do so, we use a special transformer model that we fine tune with our event and sentence training set. In our case, we use BART model which contains a BERT encoder (bidirectional) and a GPT decoder (left ot right)."
      ],
      "metadata": {
        "id": "BQDON45N_O2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset creation"
      ],
      "metadata": {
        "id": "IgvGqoXNNMSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we create our complete training set which consist of a dictionnary of event and associated sentence that we put in a dataset :"
      ],
      "metadata": {
        "id": "OREcZychN3bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainEvent2Sent = {**trainPromptEvent2Sent,**trainStoriesEvent2Sent}"
      ],
      "metadata": {
        "id": "HtTPEPefKyHs"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxExemples = 200"
      ],
      "metadata": {
        "id": "hU4WdgnEUZsC"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = random.choices(list(trainEvent2Sent.keys()), k=maxExemples)\n",
        "trainEvent2SentHandle = {}\n",
        "for i in ind:\n",
        "  trainEvent2SentHandle[i] = trainEvent2Sent[i]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tK0oxmAtLxsu"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainEvent2SentList = []\n",
        "for event in trainEvent2SentHandle.keys():\n",
        "  trainEvent2SentList += [{\"input\": event.toStringNoComa(), \"output\": trainEvent2SentHandle[event]}]\n",
        "\n",
        "trainDataset = Dataset.from_list(trainEvent2SentList)\n"
      ],
      "metadata": {
        "id": "BQZ7Q3XcfjTf"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainDataset['output'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOKZi1_m-6ID",
        "outputId": "2dd909f6-92ff-4cf8-a8f5-698b27481e19"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Being the taxi service for lost souls was no fun anymore , after years of pleading for mercy before being sent into the pits of hell , he hoped to find someone who would n't beg him for mercy , that 's where his Demon virtues ran out .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we tokenize the inputs and output with BART tokenizer to preprocess our data to fit in BART model :"
      ],
      "metadata": {
        "id": "9fviy4f0ODEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BART tokenizer\n",
        "tokenizerBART = BartTokenizer.from_pretrained('facebook/bart-base')"
      ],
      "metadata": {
        "id": "gqLtZwRhnIaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e761e1b-41af-4a11-89f4-38c553f14342"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the data\n",
        "def preprocess_function(example):\n",
        "    inputs = example[\"input\"]\n",
        "    targets = example[\"output\"]\n",
        "    model_inputs = tokenizerBART(inputs, max_length=10, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Set up the tokenizer for targets\n",
        "    labels = tokenizerBART(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenizedTrainDataset = trainDataset.map(preprocess_function, batched=False)"
      ],
      "metadata": {
        "id": "xXkcP6gI-Kpa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "f343cdc988b743dab26a1070f952e450",
            "9d5bdaa13c5f4ebf8b4053183bc327d0",
            "7c0f438da24a40c98d15cf7aae3cd598",
            "4272c5fbe82346b4836954de3bddb4da",
            "9677e65121954f258ef60324dc6622d7",
            "fec1adaf97bf4d17bf257f86385ce31e",
            "1dc89506337148b7b1b0ed7d59ea254d",
            "e5a5aad78e7e42fdb6a4737a741d50b9",
            "083d3292cb124edd98470bf4fb42c58e",
            "7efefd800a8a47bf96f988f167f43595",
            "6666b2e33c8243e4be0c60e9daa05cec"
          ]
        },
        "outputId": "3cffa90c-990f-41f0-e3fd-0f5b375efd13"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f343cdc988b743dab26a1070f952e450"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model and training"
      ],
      "metadata": {
        "id": "WzyVmCFKNTbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the seq2seq BART model that we fine tune with our training data :"
      ],
      "metadata": {
        "id": "A85pU5zsONC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the BART model\n",
        "event2SentModel = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # number of training epochs\n",
        "    per_device_train_batch_size=8,   # batch size for training\n",
        "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Set up the Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=event2SentModel,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenizedTrainDataset,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "x3p03UYYM0hB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "21718fc1-1992-4dbf-fd58-d5dcecba4d14"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 22:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>14.949900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>14.072400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>13.099500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>12.029300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>11.517500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>10.751100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>10.000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=75, training_loss=12.137869822184244, metrics={'train_runtime': 1353.5426, 'train_samples_per_second': 0.439, 'train_steps_per_second': 0.055, 'total_flos': 3536947814400.0, 'train_loss': 12.137869822184244, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "TX8rDE_KNYdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_output(input_text):\n",
        "    inputs = tokenizerBART(input_text, return_tensors=\"pt\", padding=\"max_length\", max_length=10, truncation=True)\n",
        "    outputs = event2SentModel.generate(inputs[\"input_ids\"], max_length=50)\n",
        "    output_text = tokenizerBART.decode(outputs[0], skip_special_tokens=True)\n",
        "    return output_text\n",
        "\n",
        "# Example usage\n",
        "input_event = testPairsEvent[0][1].toStringNoComa()\n",
        "output_sentence = generate_output(input_event)\n",
        "print(output_sentence)"
      ],
      "metadata": {
        "id": "QU-oxPqde3Te",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4335a4c-9503-4681-8764-2d69c755adf9"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All they had to do was hold their hands and handed them over to them, they said they had no idea what to do with them and they all had to go back to their places and put them back where they belonged to them All\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testPairsEvent[0][1].toStringNoComa())"
      ],
      "metadata": {
        "id": "IZUaGuMztxIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b301046e-4577-4eeb-9db8-da4bb306c2a3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it do they NoObject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evalutation"
      ],
      "metadata": {
        "id": "3dA0noKkNCXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use again the perplexity and BLEU metrics to evaluate our event2sentence model :"
      ],
      "metadata": {
        "id": "9YcWVLdENa9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateSentencePerplexity(testSet, vocab):\n",
        "    perplexityScore = 0\n",
        "    for event in testSet.keys():\n",
        "        prediction = generate_output(event.toStringNoComa())\n",
        "        perplexityScore += perplexity(prediction, vocab)\n",
        "    return perplexityScore / len(testSet)"
      ],
      "metadata": {
        "id": "C5Qx6I1HPxGb"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testEvent2Sent = {**testPromptEvent2Sent,**testStoriesEvent2Sent}"
      ],
      "metadata": {
        "id": "NhU_HN1JRNwL"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = random.choices(list(testEvent2Sent.keys()), k=int(maxExemples*0.2))\n",
        "testEvent2SentHandle = {}\n",
        "for i in ind:\n",
        "  testEvent2SentHandle[i] = testEvent2Sent[i]"
      ],
      "metadata": {
        "id": "fXPiJCR8BqWs"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perp = evaluateSentencePerplexity(testEvent2SentHandle, vocab)"
      ],
      "metadata": {
        "id": "9gWd7na_SNjD"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(perp)"
      ],
      "metadata": {
        "id": "p1K6EXC1SUtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b176e56-f2c9-4d5f-aeea-4a28a2959838"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2169382327246394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For BLEU, it would be better to use only references sentences that are created from the same event. But here, we lack of a good training set that would give enough sentences for the same event to give a relevant score (at least we lack of a relevant number of examples that we can process on my computer). Then we use only one reference to compute the BLEU score."
      ],
      "metadata": {
        "id": "JiBD6mwKSp0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateBLEU(testSet):\n",
        "    total_bleu_score = 0\n",
        "    for event in testSet.keys():\n",
        "        prediction = generate_output(event.toStringNoComa())\n",
        "        bleu_score = tr.bleu_score.sentence_bleu([testSet[event]], prediction, smoothing_function=tr.bleu_score.SmoothingFunction().method1)\n",
        "        total_bleu_score += bleu_score\n",
        "\n",
        "    return total_bleu_score / len(testSet)\n"
      ],
      "metadata": {
        "id": "sxiQsLoOSh_O"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_bleu_score = evaluateBLEU(testEvent2SentHandle)\n",
        "print(f\"Average BLEU Score: {average_bleu_score}\")"
      ],
      "metadata": {
        "id": "EBpQTYKiUED6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f22296-b7f2-4333-dcce-6e0a8cbdcd32"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 0.11100920541875847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Combining event2event with event2sentence"
      ],
      "metadata": {
        "id": "9ZV5aTuuGkGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can try to combine our two model to create a logical story."
      ],
      "metadata": {
        "id": "rl3H9mJeUagL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prediction"
      ],
      "metadata": {
        "id": "ZRTMD6JWUoBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "startSent = \"I am a dangerous wizard\"\n",
        "eventVocab.addSentence(startSent)\n",
        "print(startSent)\n",
        "_, startEvents = eventCreator(startSent)\n",
        "startEvent = startEvents[0]\n",
        "storyLength = 10\n",
        "inputTensor = tensorFromEvent(eventVocab, startEvent)\n",
        "for i in range(storyLength):\n",
        "  outputTensor = makePrediction(inputTensor)\n",
        "  strEvent = sentenceFromTensor(eventVocab, outputTensor)\n",
        "  strEvent = \" \".join(strEvent)\n",
        "  outputSentence = generate_output(strEvent)\n",
        "  print(outputSentence)\n",
        "  inputTensor = outputTensor\n"
      ],
      "metadata": {
        "id": "hScoUkevGyXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a3849e2-1f29-4199-c767-76d4c8b09ab8"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am a dangerous wizard\n",
            "I will be I No.\n",
            "He would be glad to be rid of all of them, he said.  Â   \n",
            "I be what I was, I be what he was  \n",
            "I be what I am, I be all all of them.   \n",
            "I be what I wish I could be...   Â\n",
            "I be what I said I wanted to be and I was right.\n",
            " he said, \"I had no choice in what I had to do... \" he said,,, and,.,, or,,.., or �,,.\", \", or...\"\n",
            "I be a little surprised at what I was told.\n",
            "I be what I was. I be who I am. I am who I was...\n",
            "I be what I am, and I be who I am.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def storyGeneration(vocab, startSentence, storyLength):\n",
        "    vocab.addSentence(startSentence)\n",
        "    outputStory = startSentence\n",
        "    _, startEvents = eventCreator(startSentence)\n",
        "    startEvent = startEvents[0]\n",
        "    inputTensor = tensorFromEvent(vocab, startEvent)\n",
        "    outputEvents = startEvent.toStringNoComa()\n",
        "    for i in range(storyLength):\n",
        "        outputStory += '\\n'\n",
        "        outputTensor = makePrediction(inputTensor)\n",
        "        strEvent = sentenceFromTensor(vocab, outputTensor)\n",
        "        strEvent = \" \".join(strEvent)\n",
        "        outputEvents += ' ' + strEvent\n",
        "        outputSentence = generate_output(strEvent)\n",
        "        outputStory += outputSentence\n",
        "        inputTensor = outputTensor\n",
        "    return outputEvents, outputStory"
      ],
      "metadata": {
        "id": "hY9DB_bHSIH6"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events, story = storyGeneration(eventVocab,'earth is a red egg', 20)"
      ],
      "metadata": {
        "id": "VhCU52RkTVXu"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(events)"
      ],
      "metadata": {
        "id": "l1v74ubxTh8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf3267b-f00c-4b90-eeaf-4ba544603516"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "earth be egg NoObject department laugh little less I contradict other NoObject I spy torture NoObject I catch job NoObject I be pamphlet NoObject I spend life NoObject I be I NoObject I be glass NoObject I be what NoObject I be what NoObject I be what NoObject I be what NoObject I be what NoObject I be what NoObject I be what NoObject I be what NoObject I be what NoObject I be what NoObject I be what NoObject I be what NoObject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(story)"
      ],
      "metadata": {
        "id": "WQIO7NHrTzii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3b773e-d8b8-4c14-83f5-aea4531d1117"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "earth is a red egg\n",
            "department store clerkships iced tea iced water   iced up iced iced over iced cold iced hot iced chapped iced ice iced salt iced skied water iced mint iced\n",
            "I contradict myself.\n",
            "I was told that I had to do something I could not do again. I was forced to put up with it.\n",
            "I thought I had done a good job, and I was happy to be here.\n",
            "I was stunned by the response I got. I thought that was the answer I wanted. I was wrong.\n",
            "ug-handed or izlifted iz ipipiplawed  ips   `  ip ip- ips-  iced- ip ­ ip­  � \n",
            "I am not a man. I am a man...\n",
            "I can't stand to be left alone in the dark.   \n",
            "I be who I am and I will be what I am. \n",
            "\"I'm not sure I am,\" he said.\n",
            "I be what I said I be what i be.\n",
            "I knew I was doing what I was supposed to do.\n",
            "I was held to be held down in the mowed down by the Holy gram   I was held down to be represented by the mout    he was held out as he was being  threatened  . \n",
            "I am what I would have done if I had known about them. I was what I had heard about them all the time. I could have them all caught up in their anger.  ��   � �   \n",
            "- which which by and by and and and which and and// and or supporting and/ and supporting supporting and passing and passing passing and supporting and supporting or or passing and and supporting/ supporting passing or passing passing passing or supporting or\n",
            "I be what I wanted to be.   \n",
            "I said no, I said what I was saying was what I thought was right, and what I am saying it was true.\n",
            "I don't know what to say, but I do know that\n",
            "I be who I am and what I want to do with my life.\n",
            "I be what I am, I am who I am.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluation"
      ],
      "metadata": {
        "id": "0Tas5mAgUtKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again we use our classical mesure of perplexity to mesure linguistic logic and BLEU to use story logic. A totaly subjective human evaluation is also provided in the report."
      ],
      "metadata": {
        "id": "Zg2A5PYaU1MF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "need one prompt event as input test and the story as output test"
      ],
      "metadata": {
        "id": "ID9jN2DhVXng"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kgkS9ijAUsfy"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) CEvent"
      ],
      "metadata": {
        "id": "kH8ssd9DuZfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Idea of adding character : add a relevant storyline with changing character embedding along the story."
      ],
      "metadata": {
        "id": "6D9RAJ7vZPGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our baseline with event representation for story generation, we will try to add character embedding to our event to enhance the generation of event2event model. We call this model CEvent2CEvent, and we need to define what a Cevent (Character Event) is."
      ],
      "metadata": {
        "id": "MdkFANjTu3fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use again our representation of Event with s the subject, v the verb, o the object and m an optional modifier. But now, we consider that the event can include a character (either the subject or the object). To add this consideration, we can use a new representation of event :\n",
        "e = (s,v,o,m,c)\n",
        "\n",
        "with c the embedding of the character. The best way would be to add directly the character embedding instead of the subject or modifier embedding. But by doing that, we need to change our encoder/decoder model and it would be too much costly for the computer to train (need a matrix from vocab dimension to hidden dimension rather than 1$\\times$hd). Then we add the character embedding to the end of the event and add each word caracterization of the character as a next world in our RNN encoder. Then, we get an input such that :\n",
        "\n",
        "$$e = (s,v,o,m,c_1, ..., c_k)$$\n",
        "\n",
        "where $c_1$ ... $c_k$ are the words for the character embedding.\n"
      ],
      "metadata": {
        "id": "kesOJrj1v2mY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cevent Creation"
      ],
      "metadata": {
        "id": "syt7-_8d6nN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we now need to create character embedding that grows along the story :"
      ],
      "metadata": {
        "id": "kit6BicCaCnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getCharacterEmbeddingFromTokenizedSentence(tokenizedSentence, previousCharacterDict):\n",
        "  characterSet = set()\n",
        "  for token in tokenizedSentence:\n",
        "    if (not(token.ent_iob_ in entityToRemove)) and (not(token.ent_type_ in entityTypeToRemove)):\n",
        "      characterSet.add(token.lemma_)\n",
        "    elif (token.lemma_ == \"I\") or (token.lemma_ == \"you\"):\n",
        "      characterSet.add(token.lemma_)\n",
        "  #create character dict to store word related to characters\n",
        "  characterDict = previousCharacterDict\n",
        "  for character in characterSet:\n",
        "    if not(character in characterDict.keys()):\n",
        "      characterDict[character] = []\n",
        "\n",
        "  #search for word related to character\n",
        "  for token in tokenizedSentence:\n",
        "    if (token.lemma_ in characterSet):\n",
        "      if (token.head.pos_ == 'VERB') or (token.head.pos_ == 'ADJ') or (token.head.pos_ == 'NOUN'):\n",
        "         characterDict[token.lemma_].append(token.head.lemma_)\n",
        "      if (token.head.pos_ == 'AUX') or (token.head.pos_ == 'NOUN'):\n",
        "        for t in token.head.children:\n",
        "          if (t.pos_ == 'ADJ'):\n",
        "            characterDict[token.lemma_].append(t.lemma_)\n",
        "    elif (token.head.lemma_ in characterSet):\n",
        "      if (token.pos_ == 'VERB') or (token.pos_ == 'ADJ') or (token.head.pos_ == 'NOUN'):\n",
        "        characterDict[token.head.lemma_].append(token.lemma_)\n",
        "  return characterDict, characterSet"
      ],
      "metadata": {
        "id": "1g0BrYRTu3CL"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CEvent:\n",
        "  def __init__(self, subject = None, verb = None, o = None, modifier = None, character = None):\n",
        "    self.subject = subject\n",
        "    self.verb = verb\n",
        "    self.obj = o\n",
        "    self.modifier = modifier\n",
        "    self.character = character  #list of word defining the character\n",
        "\n",
        "\n",
        "  def character2String(self):\n",
        "    output = ''\n",
        "    for word in self.character:\n",
        "      output += \", \" + word\n",
        "    return output\n",
        "\n",
        "  def character2StringNoComa(self):\n",
        "    output = ''\n",
        "    for word in self.character:\n",
        "      output += \" \" + word\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "  def toString(self):\n",
        "    return str(self.subject) + \", \" + str(self.verb) + \", \" + str(self.obj) + \", \" + str(self.modifier) + self.character2String()\n",
        "\n",
        "  def toStringNoComa(self):\n",
        "    return str(self.subject) + \" \" + str(self.verb) + \" \" + str(self.obj) + \" \" + str(self.modifier) + self.character2StringNoComa()\n",
        "\n",
        "  def toList(self):\n",
        "    return [self.subject, self.verb, self.obj, self.modifier] + self.character\n"
      ],
      "metadata": {
        "id": "BCh-f4EcvLDG"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGjA1dNlzMTP"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fixCharacter(characterSet, characterDict, subj, o):\n",
        "    if not characterSet:\n",
        "        character = ['NoObject']\n",
        "    elif subj.lemma_ in characterSet :\n",
        "        character = characterDict[subj.lemma_].copy()\n",
        "    elif o.lemma_ in characterSet:\n",
        "        character = characterDict[o.lemma_].copy()\n",
        "    else :\n",
        "        character = ['NoObject']\n",
        "    return character\n",
        "\n",
        "\n",
        "\n",
        "def cEventCreator(story):\n",
        "  cEvent2Sent = {}\n",
        "  totalCEventList = []\n",
        "  characterDict = {}\n",
        "  for sent in nlp(story).sents:\n",
        "    cEventList = []\n",
        "    characterDict, characterSet = getCharacterEmbeddingFromTokenizedSentence(sent, characterDict)\n",
        "    for token in sent:\n",
        "      #create an event from a subject\n",
        "      if token.dep_ in subjTypes:\n",
        "        subj = token\n",
        "        verb = subj.head\n",
        "        if verb.pos_ in verbTypes:\n",
        "          verbList = []\n",
        "          verbList = searchVerbsDependencies(verb, verbList)\n",
        "\n",
        "          for v in verbList:\n",
        "            if len(v[1]) == 0:\n",
        "              character = fixCharacter(characterSet, characterDict, subj, subj)\n",
        "              for m in v[2]:\n",
        "                cEventList.append(CEvent(subj.lemma_, v[0].lemma_, \"NoObject\", m.lemma_, character))\n",
        "            elif len(v[2]) == 0:\n",
        "              for o in v[1]:\n",
        "                character = fixCharacter(characterSet, characterDict, subj, o)\n",
        "                cEventList.append(CEvent(subj.lemma_, v[0].lemma_, o.lemma_, \"NoObject\", character))\n",
        "            else:\n",
        "              for o in v[1]:\n",
        "                character = fixCharacter(characterSet, characterDict, subj, o)\n",
        "                for m in v[2]:\n",
        "                  cEventList.append(CEvent(subj.lemma_, v[0].lemma_, o.lemma_, m.lemma_, character))\n",
        "      for event in eventList:\n",
        "        cEvent2Sent[event] = sent.text\n",
        "    totalCEventList += cEventList\n",
        "  return event2Sent, totalCEventList\n"
      ],
      "metadata": {
        "id": "WYYGTFeQvHwS"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cEvent2Sent, cEventList = cEventCreator(processedStories[10])"
      ],
      "metadata": {
        "id": "mJuK90i0u0ZY"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processedStories[10]"
      ],
      "metadata": {
        "id": "O3L3-KD01kGd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45810965-d1cc-42fe-e4d2-894123eae28e"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Standing on the majestic rooftop of a dead man 's manor his yellow eyes were spying the scene taking place below . Purple cape swirling in the wind , he moved his gaze upward to eye the city left for him ; the city he had sworn to protect when no one else was left to do so .   A surge of glee sent shivers through his thin , chemically bleached body , too exhilarating to contain a cackling laugh , only heard by its person of origin -- a man of vengeance , a man of the night , a man of comedy .   `` Harley , dear , tell me ... Does Mr. Cobblepot have any right sending his goons into Wayne Manor to steal these awfully priceless pieces of art ? '' Asked the cowl-wearing clown in a raspy voice dripping with sarcasm .   A female voice answered through the radio attached to the green , leathery torso of his suit :   `` No sir , Mr. J . The penguin-man surely has no right to the bat 's nicest belongings . ''   `` I did n't think so , my dear . ''   In a swift and daring motion the winged clown leapt off the edge of the building , falling nearly ten feet before the purple mantle caught the air ; allowing him to sail gracefully downward .   `` Th -- The Bat ! '' Shouted one of the masked penguin followers fearfully as the sound of the cape whipped the air .   `` Batman 's dead , dumbass , '' another responded as maniacal laughter descended upon him . The goon did n't have time to realize his error before a metal plated heel cracked his skull and both he and the ancient vase he was carrying were sent crashing toward the ground . A pile of possibly-crippled-criminal and colorful somewhat-reformed-psychotic-antihero now sat in front of Wayne Manor as the rest of the plundering goons stood frozen in place . The green and purple silently rose into a gangly figure .   `` Now I may not know much about gainful employment , but I do think stealing from the cold , dead hands of an honorable philanthropist will look bad on your resumé . ''   `` What the -- , '' were the only words spoken before the clown-bat sprang into action . In a flurry of wild strikes and bone-breaking attacks the penguin-men suffered and fell . The Batman was never this vicious .   As the dust settled the maniacal avenger stood silently , contemplating the future .   `` Oh , I 'll miss him , '' said the Clown .   `` You 'll always be *my* hero , Mr . J . ''   `` Shut up , baby , I know it . ''     -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --     Edit : Formatting and made some slight alterations .   Also the last line is a quote from Futurama . I do n't actually watch the show but saw it somewhere else on Reddit and thought it was funny so I decided to use it here . # DirtyPlagiarism # SorryForUsingHashtags\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cEvent in cEventList:\n",
        "  print(cEvent.toString())"
      ],
      "metadata": {
        "id": "FBd73g0y0Nva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4618579c-09e2-4957-da5c-fae2e84628c1"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stand, spy, scene, NoObject, NoObject\n",
            "he, eye, city, NoObject, NoObject\n",
            "he, move, gaze, NoObject, NoObject\n",
            "surge, contain, laugh, NoObject, NoObject\n",
            "surge, send, shiver, NoObject, NoObject\n",
            "Cobblepot, have, right, NoObject, have\n",
            "voice, answer, NoObject, sir, NoObject\n",
            "man, have, right, NoObject, NoObject\n",
            "clown, catch, air, NoObject, NoObject\n",
            "mantle, catch, air, NoObject, NoObject\n",
            "sound, whip, air, NoObject, NoObject\n",
            "goon, have, time, NoObject, NoObject\n",
            "heel, crack, skull, NoObject, NoObject\n",
            "I, know, much, NoObject, tell, think, know, think\n",
            "avenger, contemplate, future, NoObject, NoObject\n",
            "I, miss, he, NoObject, tell, think, know, think, miss\n",
            "Clown, miss, he, NoObject, NoObject\n",
            "you, be, hero, NoObject\n",
            "I, know, it, NoObject, tell, think, know, think, miss, know\n",
            "line, be, quote, NoObject, NoObject\n",
            "I, see, it, NoObject, tell, think, know, think, miss, know, watch, decide\n",
            "I, use, it, NoObject, tell, think, know, think, miss, know, watch, decide\n",
            "I, watch, show, NoObject, tell, think, know, think, miss, know, watch, decide\n",
            "I, use, it, NoObject, tell, think, know, think, miss, know, watch, decide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UeDAjRd6Qxxl"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data train creation"
      ],
      "metadata": {
        "id": "uDWTs1oj6hq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we can create our cEvent and our cEvent2SentenceDict, we need to create cEvent pairs :"
      ],
      "metadata": {
        "id": "WKIdQLx13X9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createCEventsFromPrompts(prompts):\n",
        "  promptCEvents = []\n",
        "  promptCEvent2Sent = {}\n",
        "  for prompt in prompts:\n",
        "    cEventDict, cEventList = cEventCreator(prompt)\n",
        "    promptCEvents.append(cEventList)\n",
        "    promptCEvent2Sent.update(cEventDict)\n",
        "  return promptCEvent2Sent, promptCEvents\n",
        "\n",
        "def createCEventsFromStories(stories):\n",
        "  storiesCEvents = []\n",
        "  storiesCEvent2Sent = {}\n",
        "  for story in stories:\n",
        "    cEventDict, cEventList = cEventCreator(story)\n",
        "    storiesCEvents.append(cEventList)\n",
        "    storiesCEvent2Sent.update(cEventDict)\n",
        "  return storiesCEvent2Sent, storiesCEvents"
      ],
      "metadata": {
        "id": "2Q0UFurg0eOy"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPromptCEvent2Sent, trainPromptsCEvents = createCEventsFromPrompts(trainProcessedPrompts)\n",
        "trainStoriesCEvent2Sent, trainStoriesCEvents = createCEventsFromStories(trainProcessedStories)"
      ],
      "metadata": {
        "id": "7AiTVP6Y4pG3"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testPromptCEvent2Sent, testPromptsCEvents = createCEventsFromPrompts(testProcessedPrompts)\n",
        "testStoriesCEvent2Sent, testStoriesCEvents = createCEventsFromStories(testProcessedStories)"
      ],
      "metadata": {
        "id": "M-5I4YG-4bdv"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPairsCEvent = []\n",
        "for j in range(len(trainPromptsCEvents)):\n",
        "    concat = trainPromptsCEvents[j] + trainStoriesCEvents[j]\n",
        "    for i in range(len(concat) - 1):\n",
        "        trainPairsCEvent.append([concat[i],concat[i+1]])"
      ],
      "metadata": {
        "id": "AiXXCTy34k7z"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainPairsCEvent[200][0].toString() + \" -> \" + trainPairsCEvent[200][1].toString())"
      ],
      "metadata": {
        "id": "BsoyAhtu5IDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d697c0c-c683-4681-bf0d-fcd1432fe88d"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we, buy, time, NoObject, NoObject -> defender, buy, time, NoObject, NoObject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testPairsCEvent = []\n",
        "for j in range(len(testPromptsCEvents)):\n",
        "    concat = testPromptsCEvents[j] + testStoriesCEvents[j]\n",
        "    for i in range(len(concat) - 1):\n",
        "        testPairsCEvent.append([concat[i],concat[i+1]])"
      ],
      "metadata": {
        "id": "05n9x_ru5LGn"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cEventVocab = Vocab('ceventVocab')\n",
        "for pair in trainPairsCEvent:\n",
        "    for token in pair[0].toList():\n",
        "        if not(token == \"NoObject\"):\n",
        "            cEventVocab.addWord(token)\n",
        "    for token in pair[1].toList():\n",
        "        if not(token == \"NoObject\"):\n",
        "            cEventVocab.addWord(token)\n",
        "for pair in testPairsCEvent:\n",
        "    for token in pair[0].toList():\n",
        "        if not(token == \"NoObject\"):\n",
        "            cEventVocab.addWord(token)\n",
        "    for token in pair[1].toList():\n",
        "        if not(token == \"NoObject\"):\n",
        "            cEventVocab.addWord(token)"
      ],
      "metadata": {
        "id": "IAk2dAhh5VmA"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxCEventToken = 25\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "u-I4vEm38t7v"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDataloaderCevent(batch_size, pairs, vocab):\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, maxCEventToken), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, maxCEventToken), dtype=np.int32)\n",
        "\n",
        "    for idx, pair in enumerate(pairs):\n",
        "        inp_tensor, tgt_tensor = tensorsFromPair(vocab, pair)\n",
        "\n",
        "        input_ids[idx, :min(len(inp_tensor),maxCEventToken)] = inp_tensor[:min(len(inp_tensor),maxCEventToken)].squeeze()\n",
        "        target_ids[idx, :min(len(tgt_tensor),maxCEventToken)] = tgt_tensor[:min(len(tgt_tensor),maxCEventToken)].squeeze()\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    trainDataloaderCevent = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return trainDataloaderCevent"
      ],
      "metadata": {
        "id": "JSueRAY36LSz"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDLCevent = getDataloaderCevent(batch_size, testPairsCEvent[:500], cEventVocab)"
      ],
      "metadata": {
        "id": "mQG_dFZ18nUP"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(trainDLCevent))\n",
        "print(train_features[0])\n",
        "print(train_labels[0])"
      ],
      "metadata": {
        "id": "cabriRGk9NR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d91acb-d900-4687-ceab-c300453018f0"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   9,  229,   23,    0, 1429,  229,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0])\n",
            "tensor([   9, 2756,   31,    0, 1429,  229, 2757,   61,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model for Cevent2Cevent"
      ],
      "metadata": {
        "id": "dHJbTgJQ-kZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take our previous model that we get into one class to make everything clear"
      ],
      "metadata": {
        "id": "l9YuvrAcTKQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CEvent2CEvent():\n",
        "  def __init__(self, hidden_size, vocab, maxCEventToken):\n",
        "    self.encoder = RNNEncoder(1, hidden_size)\n",
        "    self.decoder = RNNDecoder(hidden_size, vocab.n_words)\n",
        "    self.maxCEventToken = maxCEventToken\n",
        "\n",
        "\n",
        "  def train_epoch(self, dataloader, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "      for i in range(len(batch)):\n",
        "        input_tensor  = batch[0][i]\n",
        "        target_tensor = batch[1][i]\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        hidden_tensor = self.encoder.init_hidden()\n",
        "\n",
        "        for inp in input_tensor:\n",
        "            hidden_tensor = self.encoder(inp.view(1,1), hidden_tensor)\n",
        "\n",
        "        outputs_tensor = torch.zeros(len(target_tensor),self.decoder.output_size)\n",
        "\n",
        "        for trt in range(len(target_tensor)):\n",
        "            output_tensor, hidden_tensor = self.decoder(hidden_tensor)\n",
        "            outputs_tensor[trt] = output_tensor\n",
        "\n",
        "        #print(outputs_tensor)\n",
        "        loss = criterion(outputs_tensor, target_tensor.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "  def trainModel(self, train_dataloader, n_epochs, learning_rate=0.001, print_every=25, plot_every=25):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = torch.optim.Adam(self.encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = torch.optim.Adam(self.decoder.parameters(), lr=learning_rate)\n",
        "    encoder_scheduler = torch.optim.lr_scheduler.StepLR(encoder_optimizer, step_size=50, gamma=0.5)\n",
        "    decoder_scheduler = torch.optim.lr_scheduler.StepLR(decoder_optimizer, step_size=50, gamma=0.5)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = self.train_epoch(train_dataloader, encoder_optimizer, decoder_optimizer,  criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        encoder_scheduler.step()\n",
        "        decoder_scheduler.step()\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "  def train(self, trainDataLoader, n_epochs):\n",
        "    self.trainModel(trainDL, n_epochs)\n",
        "\n",
        "\n",
        "  def makePrediction(self, input_tensor):\n",
        "    encoder_hidden = self.encoder.init_hidden()\n",
        "    input_length = input_tensor.size(0)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_hidden = self.encoder(input_tensor[ei].view(1,1), encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.zeros(input_length, device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_outputs = torch.zeros(input_length, dtype=torch.long, device=device)\n",
        "\n",
        "    for di in range(self.maxCEventToken):\n",
        "        decoder_output, decoder_hidden = self.decoder(decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1) #return the largest element of the tensor\n",
        "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "        decoder_outputs[di] = topi.long()\n",
        "    return decoder_outputs\n",
        "\n",
        "  def makePredictionFromPair(self, pairEvent, vocab):\n",
        "    input_tensor, target_tensor = tensorsFromPair(vocab, pairEvent)\n",
        "    return makePrediction(input_tensor)\n",
        "\n",
        "\n",
        "  def evaluateCEventPerplexity(self, testSet, vocab):\n",
        "    perplexityScore = 0\n",
        "    for pair in testSet:\n",
        "      prediction = sentenceFromTensor(vocab, makePredictionFromPair(pair).tolist())\n",
        "      perplexityScore += perplexity(prediction, vocab)\n",
        "    return perplexityScore / len(testSet)\n",
        "\n",
        "  def evaluateBLEU(self, testSet, vocab):\n",
        "    total_bleu_score = 0\n",
        "    for pair in testSet:\n",
        "      prediction = sentenceFromTensor(vocab, makePredictionFromPair(pair).tolist())\n",
        "      bleu_score = tr.bleu_score.sentence_bleu([pair[1].toList()], prediction, smoothing_function=tr.bleu_score.SmoothingFunction().method1)\n",
        "      total_bleu_score += bleu_score\n",
        "\n",
        "    return total_bleu_score / len(testSet)\n"
      ],
      "metadata": {
        "id": "Yr_-m2a2-OHI"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 200"
      ],
      "metadata": {
        "id": "4Npm7RtaJaT6"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cEvent2CEventModel = CEvent2CEvent(hidden_size, cEventVocab, maxCEventToken)"
      ],
      "metadata": {
        "id": "vta0RdoyLoeb"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cEvent2CEventModel.train(trainDLCevent, 1000)"
      ],
      "metadata": {
        "id": "WHsASfW6N8BH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40753ea8-4072-4b82-ca49-a1ffa340a8db"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 12s (- 7m 51s) (25 2%) 9.7278\n",
            "0m 27s (- 8m 40s) (50 5%) 7.1547\n",
            "0m 39s (- 8m 6s) (75 7%) 6.6379\n",
            "0m 55s (- 8m 18s) (100 10%) 6.4251\n",
            "1m 7s (- 7m 52s) (125 12%) 6.0096\n",
            "1m 23s (- 7m 51s) (150 15%) 5.9277\n",
            "1m 35s (- 7m 29s) (175 17%) 5.8079\n",
            "1m 50s (- 7m 21s) (200 20%) 5.6285\n",
            "2m 3s (- 7m 5s) (225 22%) 5.7123\n",
            "2m 17s (- 6m 53s) (250 25%) 5.4967\n",
            "2m 30s (- 6m 37s) (275 27%) 5.5774\n",
            "2m 47s (- 6m 29s) (300 30%) 5.4636\n",
            "3m 1s (- 6m 17s) (325 32%) 5.4708\n",
            "3m 15s (- 6m 3s) (350 35%) 5.3954\n",
            "3m 32s (- 5m 54s) (375 37%) 5.3830\n",
            "3m 49s (- 5m 44s) (400 40%) 5.4477\n",
            "4m 3s (- 5m 28s) (425 42%) 5.4026\n",
            "4m 17s (- 5m 14s) (450 45%) 5.3909\n",
            "4m 30s (- 4m 58s) (475 47%) 5.3858\n",
            "4m 44s (- 4m 44s) (500 50%) 5.3849\n",
            "4m 57s (- 4m 29s) (525 52%) 5.2630\n",
            "5m 12s (- 4m 15s) (550 55%) 5.5076\n",
            "5m 24s (- 4m 0s) (575 57%) 5.3469\n",
            "5m 39s (- 3m 46s) (600 60%) 5.3426\n",
            "5m 52s (- 3m 31s) (625 62%) 5.4101\n",
            "6m 7s (- 3m 17s) (650 65%) 5.3779\n",
            "6m 20s (- 3m 3s) (675 67%) 5.5151\n",
            "6m 34s (- 2m 49s) (700 70%) 5.4750\n",
            "6m 47s (- 2m 34s) (725 72%) 5.2736\n",
            "7m 3s (- 2m 21s) (750 75%) 5.3989\n",
            "7m 17s (- 2m 7s) (775 77%) 5.3406\n",
            "7m 34s (- 1m 53s) (800 80%) 5.3625\n",
            "7m 52s (- 1m 40s) (825 82%) 5.2883\n",
            "8m 5s (- 1m 25s) (850 85%) 5.2797\n",
            "8m 20s (- 1m 11s) (875 87%) 5.4303\n",
            "8m 33s (- 0m 57s) (900 90%) 5.4416\n",
            "8m 48s (- 0m 42s) (925 92%) 5.4598\n",
            "9m 2s (- 0m 28s) (950 95%) 5.3328\n",
            "9m 18s (- 0m 14s) (975 97%) 5.3372\n",
            "9m 30s (- 0m 0s) (1000 100%) 5.4094\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexityScore = cEvent2CEventModel.evaluateCEventPerplexity(testPairsCEvent, cEventVocab)"
      ],
      "metadata": {
        "id": "qugYDI25V8XC"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(perplexityScore)"
      ],
      "metadata": {
        "id": "9q12w4DMWGq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d039aac-d344-4599-9070-c4e78606a0ca"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0478092733391324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BLEUScore = cEvent2CEventModel.evaluateBLEU(testPairsCEvent, cEventVocab)"
      ],
      "metadata": {
        "id": "8U5PdsllOB5h"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(BLEUScore)"
      ],
      "metadata": {
        "id": "HjvOSbOUV0mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01ac99a-8498-4dda-f20d-f55b9d2ecbfa"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05051696794069422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model for CEvent2Sentence"
      ],
      "metadata": {
        "id": "C5jrJCoITFbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take again the BART transformers that we fine tune to generate sentence from CEvent."
      ],
      "metadata": {
        "id": "QUIgyQBGTSTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainCEvent2Sent = {**trainPromptCEvent2Sent,**trainStoriesCEvent2Sent}"
      ],
      "metadata": {
        "id": "BqMQ7fVvTI_1"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = random.choices(list(trainCEvent2Sent.keys()), k=maxExemples)\n",
        "trainCEvent2SentHandle = {}\n",
        "for i in ind:\n",
        "  trainCEvent2SentHandle[i] = trainCEvent2Sent[i]"
      ],
      "metadata": {
        "id": "X_DyMBaKUVOM"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainCEvent2SentList = []\n",
        "for event in trainCEvent2SentHandle.keys():\n",
        "  trainCEvent2SentList += [{\"input\": event.toStringNoComa(), \"output\": trainCEvent2SentHandle[event]}]\n",
        "\n",
        "trainCEventDataset = Dataset.from_list(trainCEvent2SentList)\n"
      ],
      "metadata": {
        "id": "kGrXgZtfEzxS"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the data\n",
        "def preprocess_CEvent_function(example):\n",
        "    inputs = example[\"input\"]\n",
        "    targets = example[\"output\"]\n",
        "    model_inputs = tokenizerBART(inputs, max_length=maxCEventToken, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Set up the tokenizer for targets\n",
        "    labels = tokenizerBART(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenizedTrainCEventDataset = trainCEventDataset.map(preprocess_function, batched=False)"
      ],
      "metadata": {
        "id": "RXs11oOAFI8i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a0be70dc7d224209a6b739bcd29135d4",
            "659d9b45142a4e3f996d5c7203429193",
            "9a14dbb008024defa38b16a568e4ab0b",
            "e01a832d9d004dd8a108a5fd0800ee8a",
            "e65e2108f9484274b5fcaa888313ce1d",
            "27369bb7606a4beeb2b19d88e9838579",
            "711ffd6bc7a645e8a2dba35c0fffb069",
            "d9800fc286ec4d50a30c92465c2176bc",
            "bc58fa23ace74ef3a1d078b2e842870c",
            "8674428e3b5f4ac29a4ddcdb8b563df6",
            "cbe4b97d3d5142caaf2e4e96d84fdbf9"
          ]
        },
        "outputId": "1bf7be5c-0304-4459-87ab-1f0c80874063"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/69 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0be70dc7d224209a6b739bcd29135d4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CEvent2Sent():\n",
        "  def __init__(self):\n",
        "    # Load the BART model\n",
        "    self.event2SentModel = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "\n",
        "  def setupTrainingParam(self, output_dir='./results', num_train_epochs=3, per_device_train_batch_size=8, per_device_eval_batch_size=8, warmup_steps=500, weight_decay=0.01, logging_dir='./logs', logging_steps=10):\n",
        "    # Set up training arguments\n",
        "    self.training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir= output_dir,          # output directory\n",
        "    num_train_epochs=num_train_epochs,              # number of training epochs\n",
        "    per_device_train_batch_size=per_device_train_batch_size,   # batch size for training\n",
        "    per_device_eval_batch_size=per_device_eval_batch_size,    # batch size for evaluation\n",
        "    warmup_steps=warmup_steps,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=weight_decay,               # strength of weight decay\n",
        "    logging_dir=logging_dir,            # directory for storing logs\n",
        "    logging_steps=logging_steps,\n",
        "    )\n",
        "\n",
        "  def fit(self, tokenizedTrainDataset):\n",
        "    # Set up the Trainer\n",
        "    self.trainer = Seq2SeqTrainer(\n",
        "        model=self.event2SentModel,\n",
        "        args=self.training_args,\n",
        "        train_dataset=tokenizedTrainDataset,\n",
        "    )\n",
        "\n",
        "  def train(self):\n",
        "    # Fine-tune the model\n",
        "    self.trainer.train()\n",
        "\n",
        "  def generate_output(self, input_text, maxCEventToken):\n",
        "    inputs = tokenizerBART(input_text, return_tensors=\"pt\", padding=\"max_length\", max_length=maxCEventToken, truncation=True)\n",
        "    outputs = self.event2SentModel.generate(inputs[\"input_ids\"], max_length=50)\n",
        "    output_text = tokenizerBART.decode(outputs[0], skip_special_tokens=True)\n",
        "    return output_text\n",
        "\n",
        "  def evaluateSentencePerplexity(self, testSet, vocab, maxCEventToken):\n",
        "    perplexityScore = 0\n",
        "    for event in testSet.keys():\n",
        "        prediction = self.generate_output(event.toStringNoComa(), maxCEventToken)\n",
        "        perplexityScore += perplexity(prediction, vocab)\n",
        "    return perplexityScore / len(testSet)\n",
        "\n",
        "  def evaluateBLEU(self, testSet, maxCEventToken):\n",
        "    total_bleu_score = 0\n",
        "    for event in testSet.keys():\n",
        "        prediction = self.generate_output(event.toStringNoComa(), maxCEventToken)\n",
        "        bleu_score = tr.bleu_score.sentence_bleu([testSet[event]], prediction, smoothing_function=tr.bleu_score.SmoothingFunction().method1)\n",
        "        total_bleu_score += bleu_score\n",
        "\n",
        "    return total_bleu_score / len(testSet)"
      ],
      "metadata": {
        "id": "2GoiwPurFXMr"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cEvent2SentenceGenerator = CEvent2Sent()"
      ],
      "metadata": {
        "id": "OI5E0t7HHOdn"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cEvent2SentenceGenerator.setupTrainingParam()"
      ],
      "metadata": {
        "id": "jyM2f5nlHdm-"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cEvent2SentenceGenerator.fit(tokenizedTrainCEventDataset)"
      ],
      "metadata": {
        "id": "-tlIXoR2Hh0d"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cEvent2SentenceGenerator.train()"
      ],
      "metadata": {
        "id": "Ed5HR-J2HpnN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "8058eac7-aee9-47c7-de17-0759764e7f0b"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 09:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>15.116800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>14.141300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "SI0rZ_dPKhFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testCEvent2Sent = {**testPromptCEvent2Sent,**testStoriesCEvent2Sent}\n",
        "ind = random.choices(list(testCEvent2Sent.keys()), k=int(maxExemples*0.2))\n",
        "testCEvent2SentHandle = {}\n",
        "for i in ind:\n",
        "  testCEvent2SentHandle[i] = testCEvent2Sent[i]"
      ],
      "metadata": {
        "id": "hE1p5R31HrkN"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perp = cEvent2SentenceGenerator.evaluateSentencePerplexity(testCEvent2SentHandle, vocab, maxCEventToken)"
      ],
      "metadata": {
        "id": "Z5_35QflNH9-"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(perp)"
      ],
      "metadata": {
        "id": "kc4EiNO6NNVS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae26dc2-0cc3-4cad-afc8-ed655d4f7857"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3849278355294001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_bleu_score = cEvent2SentenceGenerator.evaluateBLEU(testCEvent2SentHandle, maxCEventToken)\n",
        "print(f\"Average BLEU Score: {average_bleu_score}\")"
      ],
      "metadata": {
        "id": "MP5RzwwMNOew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c997bb-7846-40ad-a635-59a043d93e40"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 0.0758257392755145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final story generation (experimental)"
      ],
      "metadata": {
        "id": "p-S5vqd_Tb_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StoryGenerator():\n",
        "  def __init__(self, cEvent2CEvent, cEvent2Sentence):\n",
        "    self.cEvent2CEvent = cEvent2CEvent\n",
        "    self.cEvent2Sentence = cEvent2Sentence\n",
        "\n",
        "  def storyGeneration(self, vocab, startSentence, storyLength):\n",
        "      vocab.addSentence(startSentence)\n",
        "      outputStory = startSentence\n",
        "      _, startEvents = cEventCreator(startSentence)\n",
        "      startEvent = startEvents[0]\n",
        "      inpTensor = tensorFromEvent(vocab, startEvent)\n",
        "      inputTensor = torch.zeros(maxCEventToken, dtype=torch.int32)\n",
        "      inputTensor[:min(len(inpTensor),maxCEventToken)] = inpTensor[:min(len(inpTensor),maxCEventToken)].squeeze()\n",
        "      outputEvents = startEvent.toStringNoComa()\n",
        "      print(inputTensor)\n",
        "      for i in range(storyLength):\n",
        "          outputStory += '\\n'\n",
        "          outputTensor = self.cEvent2CEvent.makePrediction(inputTensor)\n",
        "          strEvent = sentenceFromTensor(vocab, outputTensor)\n",
        "          strEvent = \" \".join(strEvent)\n",
        "          outputEvents += ' ' + strEvent\n",
        "          outputSentence = self.cEvent2Sentence.generate_output(strEvent, maxCEventToken)\n",
        "          outputStory += outputSentence\n",
        "          inputTensor = outputTensor\n",
        "      return outputEvents, outputStory"
      ],
      "metadata": {
        "id": "016Dl7VOTbBX"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storyGenerator = StoryGenerator(cEvent2CEventModel, cEvent2SentenceGenerator)"
      ],
      "metadata": {
        "id": "jEp9gAqEWAMF"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ouputEvents, outputStory = storyGenerator.storyGeneration(vocab, 'earth is a red egg', 20)"
      ],
      "metadata": {
        "id": "xQZSCqa-WM-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd32f087-0129-4048-b539-5bbe47484864"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1759,    2, 5873,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputStory)"
      ],
      "metadata": {
        "id": "hVFAPNbjWNt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "424658e3-1978-4b75-daed-efc9d4bed467"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "earth is a red egg\n",
            "with flower so NoObject pungent NoObject NoObject noObject No Object NoObject YesObject NoNoObject No\n",
            "with flower so NoObject pungent NoObject NoNoObject NoObject noObject No Object NoObject YesObject Noobject No\n",
            "withholding so NoObject pungent NoObject No Object NoObject object NoObject PungentNoObject NoObjects NoObject YesObject NObject No\n",
            "with flower so NoObject pungent NoNoObject NoObject No Object NoObjects NoObject nObject Noobject NoObject noObject No\n",
            "with flower so NoObject pungent NoObject NoObject noObject No Object NoObject NObject Noobject NoObjectNoObject No\n",
            "with flower so NoObject pungent NoObject NoObject YesObject No Object NoObject NObject NoNo Object Noobject NoNoobject NoObjectNoObject Noobject YesNo NoObject Object NoNoNoNoObject Yes NoObject\n",
            "with Object NoObject No Object No Object Object Object Noobject No ObjectNoObject NoObjects NoObject YesObject Yes Object No NoObject Object No object No Object\n",
            "with flower so NoObject pungent NoObject No Object NoObjectNoObject NoObject noObject NoNo\n",
            "with flower so NoObject pungent NoObject NoObject Pungent YesObject No Object NoObject noObject No\n",
            "with No. NoObject No Object NoNoNoObject NoNo Object No NoObject Yes No No NoNoobject No No\n",
            "with flower so NoObject pungent NoObject NoObject NObject No Object NoObject OObject NoNoObject Noobject NoObject YesObject N\n",
            "with flower so NoObject pungent No Object NoObject NoObject Pungent noObject No ObjectPungent NObject Noobject No Object\n",
            "with flower so NoObject pungent NoObject NoObject Object NoNoObject No Object NoObject YesObjects No\n",
            "with flower so NoObject pungent NoObject NoObject NObject Noobject NoObject YesObject No Object NoObject nObject No object NoObjectnObject No\n",
            "with Object NoObject NoObjects NoObject So NoObject pungent NoObject YesObject Noobject NoObjectNoObject No\n",
            "withwith NoObject NoObject pungentwith Noobject NoObject noObject No Object NoObject Pungent NoObjectsNoObjects NoObject Object No Object noObject Object Object ObjectObject No\n",
            "with flower so NoObject pungent NoObject NoObject noObject No Object NoObject Yes NoObjectNoObject No\n",
            "with flower so NoObject pungent No Object NoObject NoObject YesNoObject No Object YesObject Noobject NoObject noObject NoNo Object No ObjectNObject NoVellum NoObjectNoObjects NoNoobject No\n",
            "with flower so NoObject NoObject pungent NoNoNo No No NoNoObject No Object No. NoNo Noobject NoNo Object NoNoobject NoObject Yes No No\n",
            "with flower so NoObject pungent NoObject No Object NoObject YesObject Noobject NoObject noObject NoObject nObject No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuoTCBEfxmho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}